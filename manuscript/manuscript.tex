\documentclass[twocolumn]{article}
\usepackage[left=0.7in,right=0.7in,top=1in,bottom=1in]{geometry}
\setlength{\columnsep}{2\columnsep}
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{siunitx}
\usepackage[round,authoryear,sort]{natbib}
\usepackage{url}
\usepackage[pdftex,colorlinks=true]{hyperref}
\usepackage{fancyhdr}
\usepackage{multirow}
\usepackage{booktabs}

% Define special units
\DeclareSIUnit\mgal{\milli Gal}

% Define inverse symbol with shorter minus
\newcommand{\inv}{^{\text{-}1}}
\newcommand{\trans}{^{\text{T}}}

% Import files with parameter values generated by notebooks
\newcommand{\Gal}{Gal}
\input{synthetic-surveys.tex}
\input{parameters-ground-survey.tex}
\input{parameters-airborne-survey.tex}
\input{best-parameters-ground-survey.tex}
\input{best-parameters-airborne-survey.tex}
\input{source-layouts-schematics.tex}


% Define title, authors, affiliations and DOI
% ===========================================
\newcommand{\Title}{
    Gradient boosted equivalent sources
}
\newcommand{\Author}{
    S.R. Soler,
    L. Uieda
}
\newcommand{\AuthorAffil}{
    {\large
        Santiago R. Soler$^{1,2}$,
        Leonardo Uieda$^{3}$
    }
    \\[0.4cm]
    {\small $^{1}$CONICET, Argentina (santiago.r.soler@gmail.com)} \\
    {\small $^{2}$Instituto Geofísico Sismológico Volponi, UNSJ, Argentina} \\
    {\small $^{3}$Department of Earth, Ocean and Ecological Sciences, School of Environmental Sciences, University of Liverpool, UK} \\
}
\newcommand{\DOI}{
    doi:\href{https://doi.org/xxx.xxx/xxxxxx}{xxx.xxx/xxxxxx}
}
\newcommand{\DOILink}{
    \href{https://doi.org/xxx.xxx/xxxxxx}{doi.org/xxx.xxx/xxxxxx}
}


% Configure header and hypersetup
% ===============================
\pagestyle{fancy}
\fancyhf{}
\lhead{
    \fontsize{9pt}{12pt}\selectfont
    \Author{}, 2019. \DOI{}
}
\rhead{\fontsize{9pt}{12pt}\selectfont \thepage}
\renewcommand{\headrulewidth}{0pt}
\hypersetup{
    allcolors=blue,
    pdftitle={\Title},
    pdfauthor={\Author},
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title{\Title}
\author{\AuthorAffil}
\date{
    \normalsize
    \today
}
\maketitle

\begin{abstract}
    My abstract
    \\[0.5cm]
    \textbf{Keywords:}
    My keywords
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

Measurements of anomalies in potential fields, like gravity disturbances and
total-field magnetic anomalies, are widely used in geophysical exploration for
their relatively low cost of acquisition.
These data can be surveyed using ground, airborne, shipborne, or satellite
systems.
In ground surveys, the data are often gathered following irregular paths or
networks along the surface of the terrain, leading to highly variable
elevations in mountainous regions.
On airborne surveys, the data are gathered along flight lines, producing a
large number of measurements concentrated along almost straight lines.
Measurement height can also change because of the vertical movement of the
aircraft.
Processing of the data often involves interpolation onto a regular grid at
constant height, both to improve visualization for interpretation purposes as
well as to prepare the data for further processing and modelling (e.g.,
reduction-to-the-pole, derivative calculations, upward continuation, Euler
deconvolution).

Several methods exist in the literature for interpolation in two dimensions,
for example continuous curvature splines in tension \citep{smith1990},
bi-harmonic (thin-plate) splines \citep{sandwell1987}, and kriging \citep{hansen1993}.
These general-purpose methods have limitations when it comes to interpolating
potential field data:
(i) they are not able to take into account the variable height of the
observation points and
(ii) the interpolating functions are not necessarily harmonic functions, which
is the underlying assumption behind many processing techniques
(e.g., upward continuation and vertical derivatives).

A widely used method for interpolating gravity and magnetic data
is the equivalent source technique (also known as equivalent layer, radial
basis functions, or Green's functions interpolation), first introduced by
\citet{dampney1969}.
It consists in fitting a model of elementary sources to the data and using this
model to predict new data values.
Besides interpolation, equivalent sources have been used for
reduction-to-the-pole of magnetic data
\citep{silva1986, nakatsuka2006, guspi2009}, upward
continuation \citep{emilia1973, li2010}, joint processing of gravity gradient
data \citep{barnes2011}, modelling the lithospheric magnetic field
\citep{kother2015}, recovering the magnetic induction vector from
total-field magnetic anomalies \citep{li2020}, and more.

Many variants of the equivalent source technique have been proposed, often
attempting to obtain faster or more accurate solutions.
The key factors that vary between them are: (i) the type of source, (ii)
the location of the sources, and (iii) the solution strategy.
The type of source is most commonly a point mass for gravity or dipole for
magnetics \citep[e.g.,~][]{vonfrese1981, silva1986, mendonca1994, siqueira2017}.
However, right-rectangular prisms \citep[e.g.,][]{barnes2011, jirigalatu2019,
li2020} and tesseroids \citep{bouman2016} have also been used successfully.
In fact, even point sources with a simple inverse distance function, instead of
actual gravity or magnetic fields, can be used as
equivalent sources \citep{cordell1992}.
The sources are often distributed on a regular grid at a constant depth
\citep[e.g.,~][]{leao1989, barnes2011, oliveira2013}
or placed beneath each data point \citep[e.g.,~][]{cordell1992, siqueira2017}.
The model is usually estimated through damped least-squares, which imposes a
heavy computational load when the number of data points is large (e.g.,
airborne and satellite surveys).
To reduce the computational load, \citet{mendonca1994} built the solution
iteratively by incorporating one data point at a time using the ``equivalent
data concept''.
\citet{leao1989} processed the input data using a moving window, only fitting the
data inside the window and predicting observations at the center of the window.
\citet{li2010} and \citet{barnes2011} apply different operations to generate a
sparse representation of the sensitive matrix (respectively, wavelet
compression and quadtree discretization), which significantly improves the
speed of the least-squares solution.
\citet{oliveira2013} parametrized the equivalent layer as a piecewise bivariate
polynomial function, reducing the number of parameters in the solution.
\citet{siqueira2017} developed an iterative solution in which the sensitivity
matrix is transformed into a diagonal matrix with constant terms through the
``excess mass criterion''.
\citet{jirigalatu2019} applied the Gauss-FFT method to speed up the forward
modelling operations and solved the least-squares problem using steepest
descent to avoid calculating the Hessian matrix and solving linear systems.
Most existing methods solve under-determined problems, requiring a much larger
number of equivalent sources than the number of data points.
Furthermore, many of the optimizations proposed are also complex to implement
in a computer program, limiting their wider adoption.
In the present study,
we propose a two-way method for reducing the computational load needed to apply
the equivalent sources technique: first by reducing the number of equivalent
sources through a \emph{block-averaging} strategy and then simplifying the
fitting process through a \emph{gradient boosting} algorithm.
The first strategy consists in
dividing the survey area into horizontal blocks and assign one source
to each block at the median horizontal location of the data points.
For airborne surveys, which are oversampled along tracks, this can greatly
reduce the size of the inverse problem while retaining the quality of
interpolation.
The second algorithm simplifies the process of fitting a very large number of
equivalent sources by defining sets of fewer sources, whose coefficients are
fitted iteratively while minimizing a given residue.
Through tests on synthetic data, we show that: (i) the \emph{block-averaged}
sources achieve the same accuracy as a traditional equivalent layer while using
a fraction of the number of sources, and (ii) the \emph{gradient boosting}
algorithm greatly reduces the computational memory required to fit very large
datasets without scarifying predictions' accuracy.
Finally these methods are used to interpolate a 1.7 million gravity data
measurements around Australia onto a regular grid.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The equivalent sources technique}

The Green's equivalent layer theorem states that any harmonic potential field
generated by any three dimensional physical-property distribution can by
reproduced by a continuous two dimensional surface distribution.
This introduces an ambiguity on the distribution that generates
a potential field: multiple physical-property distributions can generate the
same potential field.
This represents an obstacle for determining the true shape and
physical-property distribution that generates any measured potential field.
Nevertheless this ambiguity can also be exploited for developing pre-processing
techniques like interpolating potential field data.

Approximating the continuous distribution by a finite and discrete density
distribution is the basis of the \emph{equivalent sources technique}
\citep{dampney1969}.
The most common approach is to make use of a set of point sources (the
\emph{equivalent sources}) located beneath the observation points.

A classical approach for applying the equivalent sources technique would be to
propose a set of point sources that generate the same harmonic field that has
been measured.
Lets consider a set of gravity acceleration measurements $g_z$ on points
$\{\mathbf{p}_1, \ldots, \mathbf{p}_N\}$ and a set of point sources with mass
$\{m_1, \ldots, m_M\}$ located on points
$\{\mathbf{q}_1, \ldots, \mathbf{q}_M\}$.
The point sources must generate the same gravity field as the one measured:

\begin{equation}
    g_z(\mathbf{p}) = \mathbf{A} \mathbf{m},
    \label{eq:linear-problem-g}
\end{equation}

\noindent where $g_z(\mathbf{p})$ is the vector containing the measured
field on the points $\mathbf{p}$, $\mathbf{m}$ is the vector containing the
masses of the point sources and $\mathbf{A}$ a matrix whose
elements can be obtained as the vertical component of the gravitational
acceleration measured on $\mathbf{p}$ due to the point mass on $\mathbf{q}$:

\begin{equation}
    a_{ij} = G \frac{(z_i - z_j)}{|\mathbf{p}_i - \mathbf{q}_j|^3},
\end{equation}

\noindent where
$G = \SI{6.674e-11}{\cubic\meter\per\kilogram\per\second\squared}$ is the
universal gravitational constant, $z_i$ and $z_j$ are the vertical components
of the $\mathbf{p}_i$ and $\mathbf{q}_j$ points, respectively.

By solving equation~\ref{eq:linear-problem-g} we can obtain the values of
$\mathbf{m}$ that better reproduce the measured field.
This source distribution along with the fitted masses can be used to predict
gravity values on any point where the potential field has not been measured.


\subsection{Generalized equivalent sources}

It's possible to generalize the equivalent sources technique to any harmonic
field through a Green's function problem, regardless the nature of the field.

By definition, any harmonic field $V$ must satisfy the Laplace's equation:

\begin{equation}
    \nabla^2 V = 0.
\end{equation}

Considering as boundary condition that $V$ is equal to zero at infinity, then
its fundamental solution $\psi$ (also known as Green's function or radial basis
function) must satisfy \citep[p.~210]{vladimirov1979}:

\begin{equation}
    \nabla_\mathbf{p}^2 \psi(\mathbf{p}, \mathbf{q}) =
        - 4\pi \delta(\mathbf{p}, \mathbf{q}),
\end{equation}

\noindent where $\delta(\mathbf{p}, \mathbf{q})$ is the Dirac's delta function
and $\nabla_\mathbf{p}$ symbolize the Nabla operator applied on the coordinates
$\mathbf{p}$.

The fundamental solution of any harmonic field can be obtained as follows
\citep[p.~37]{blakely1995}:

\begin{equation}
    \psi(\mathbf{p}, \mathbf{q})
    =
    \int
    \frac{\delta(\mathbf{p}, \mathbf{q})}{|\mathbf{p} - \mathbf{q}|}
    \textrm{d}v
    =
    \frac{1}{|\mathbf{p} - \mathbf{q}|}.
\end{equation}

This shows that the Green's function associated with any harmonic field is
equal to the inverse of the Euclidean distance between the evaluation and the
source points.
Thus any harmonic field $V$ can be expressed as \citep[p.~37]{blakely1995}:

\begin{equation}
    V(\mathbf{p})
    =
    \int \psi(\mathbf{p}, \mathbf{q}) \rho(\mathbf{q}) d\mathbf{q}
    =
    \int \frac{\rho(\mathbf{q})}{|\mathbf{p} - \mathbf{q}|}  d\mathbf{q},
\end{equation}

\noindent where $\rho(\mathbf{q})$ is the density distribution of a certain
physical-property evaluated on the point $\mathbf{q}$. Following
\citet{dampney1969}, this density distribution can be approximated by a finite
and discrete set of point sources located on $\{\mathbf{q}_1, \ldots,
\mathbf{q}_M\}$:

\begin{equation}
    \rho(\mathbf{q}) =
        \sum\limits_{j=1}^{M} c_j \delta(\mathbf{q} - \mathbf{q_j}),
\end{equation}

\noindent where $c_j$ is a coefficient related to the point source located on
$\mathbf{q}_j$, with the same units as the physical-property.
Then the harmonic field $V$ can be approximated by:

\begin{equation}
    V(\mathbf{p})
    =
    \sum\limits_{j=1}^{M} \frac{c_j}{|\mathbf{p} - \mathbf{q}_j|}.
    \label{eq:eql-field}
\end{equation}

In case we have measured the value of the harmonic field on points
$\{\mathbf{p}_1, \ldots, \mathbf{p}_N\}$, we can adjust the values of the $c$
coefficients so they satisfy:

\begin{equation}
    V(\mathbf{p}_i)
    =
    \sum\limits_{j=1}^{M} \frac{c_j}{|\mathbf{p}_i - \mathbf{q}_j|}
    \quad \forall i=1,\ldots,N.
\end{equation}

This system of linear equations can be written in an more algebraic way:

\begin{equation}
    \mathbf{d} = \mathbf{A} \mathbf{c}
    \label{eq:linear-problem}
\end{equation}

\noindent where $\mathbf{d}$ is a vertical vector containing the measured
values of $V$ on the observation points, $\mathbf{c}$ a vertical vector
containing the $c$ coefficients and $\mathbf{A}$ is the \emph{Jacobian matrix},
whose elements are defined as the Green's function evaluated on each pair of
points $\mathbf{p}$ and $\mathbf{q}$:

\begin{equation}
    a_{ij}
    =
    \psi(\mathbf{p}_i, \mathbf{q}_j)
    =
    \frac{1}{|\mathbf{p}_i - \mathbf{q}_j|}
\end{equation}

By solving equation~\ref{eq:linear-problem} we can obtain the values of
$\mathbf{c}$ that better reproduce the measured field.
Then they can be used to predict the value of the harmonic field on any other
point where no measurement has been taken by evaluating
equation~\ref{eq:eql-field}.


\subsection{Damped least-squares solution}
\label{sec:eql-inversion}

We can obtain the values of the source coefficients $\mathbf{c}$ that best
fit the observed field values $\mathbf{d}^o$ by minimizing the goal function

\begin{equation}
    \phi(\mathbf{c}) =
    \left[\mathbf{d}^o - \mathbf{A}\mathbf{c}\right]\trans
    \mathbf{W}
    \left[\mathbf{d}^o - \mathbf{A}\mathbf{c}\right]
    + \lambda_d\ \mathbf{c}\trans\mathbf{c}
    \ ,
    \label{eq:misfit-unscaled}
\end{equation}

\noindent where
$\mathbf{W}$ is a $N \times N$ diagonal matrix of data weights and
$\lambda_d$ is a positive \emph{damping} parameter with the same units as the
Jacobian matrix elements.
The second term on the right-hand side of the equation is a zeroth-order
Tikhonov regularization \citep{tikhonov1977} (also known as a damping
regularization or ridge regression) that is used to stabilize the solution.

The range of acceptable values for the damping parameter $\lambda_d$ will
depend on the values of the Jacobian matrix $\mathbf{A}$ and the coefficients.
Consequently, this range will vary (often dramatically) between datasets,
making it difficult to choose an appropriate value for $\lambda_d$ in practice.

To solve this issue, we first scale the Jacobian matrix so that its elements
are unitless and each column has unit variance.
We define a diagonal matrix $\mathbf{S}$

\begin{equation}
    \mathbf{S} =
    \begin{bmatrix}
      \sigma_1 & 0 & \cdots &0 \\
      0 & \sigma_2 & \cdots &0 \\
      \vdots & \vdots & \ddots & \vdots \\
      0  & 0 & \cdots & \sigma_M
    \end{bmatrix}_{M \times M}
    ,
\end{equation}

\noindent in which $\sigma_j$ is the standard deviation of the $j$-th column of
$\mathbf{A}$.
We then write the forward problem in equation~\ref{eq:linear-problem} as

\begin{equation}
    \mathbf{d}
    =
    \mathbf{A} \mathbf{S}\inv \mathbf{S} \mathbf{c}
    =
    \left[
        \mathbf{A} \mathbf{S}\inv
    \right]
    \left[
        \mathbf{S} \mathbf{c}
    \right]
    =
    \mathbf{B} \mathbf{m}
\end{equation}

\noindent where $\mathbf{B}$ is the scaled and unitless Jacobian matrix and
$\mathbf{m}$ is a vector containing scaled coefficients with the same units as
the data.

The goal function defined in equation~\ref{eq:misfit-unscaled} can be
rewritten as

\begin{equation}
    \phi(\mathbf{m}) =
    \left[\mathbf{d}^o - \mathbf{B}\mathbf{m}\right]\trans
    \mathbf{W}
    \left[\mathbf{d}^o - \mathbf{B}\mathbf{m}\right]
    + \lambda\ \mathbf{m}\trans\mathbf{m}
    \ ,
    \label{eq:misfit}
\end{equation}

\noindent where $\lambda$ is a \emph{dimensionless} damping parameter and
regularization is applied on the scaled coefficients $\mathbf{m}$ instead of
$\mathbf{c}$.

The vector of scaled coefficients $\hat{\mathbf{m}}$ that minimizes the goal
function can be found by solving the \emph{normal equation system}
\citep{menke1989}

\begin{equation}
    \left[
      \mathbf{B}\trans \mathbf{W} \mathbf{B} + \lambda \mathbf{I}
    \right]
    \hat{\mathbf{m}} =
    \mathbf{B}\trans\mathbf{W}
    \mathbf{d}^o.
\end{equation}

Once the scaled coefficients are obtained, the estimated unscaled coefficients
$\hat{\mathbf{c}}$ can be calculated by removing the scaling factor

\begin{equation}
    \hat{\mathbf{c}} = \mathbf{S}\inv \hat{\mathbf{m}} \ .
\end{equation}

\noindent The forward modeling operations used to perform predictions
(e.g., for interpolation and upward continuation) are left unchanged by
using vector $\hat{\mathbf{c}}$ instead of $\hat{\mathbf{m}}$.


\subsection{Source distributions}

How to choose how many sources to use and where to locate them are not
trivial decisions that play an important role on the accuracy of the
predictions and the computational resources needed to fit the sources'
coefficients.

The chosen distribution of sources should simultaneously reproduce the measured
data on the survey points and be able to make accurate predictions of the
measured harmonic field on non observed locations.

A high number of sources homogeneously distributed on the survey region are
capable of reproducing the observed data. Nevertheless, too many sources will
make the Jacobian matrix too large, what could introduce computational problems
like the inability of storing the matrix on memory or a high computational time
needed to fit the sources' coefficients.
On the other hand, using very few sources will undoubtedly reduce the memory
needs and lower the computational time when fitting the sources' coefficients.
Nevertheless, it could be incapable of making accurate predictions or even
reproducing the measured data if the number of sources is too low.

The choice of the source distribution could also depend on the characteristic
of the survey and how the observation points are distributed on the region.
A ground survey usually consists in observation points located along irregular
paths plus some possible scattered points.
The survey region is usually heterogeneously covered, leaving areas without any
observation.
On the other hand, an airborne survey consists in observation points located
along almost straight flight lines. The measurements are usually taken at
a high frequency, so the observation points along the flight lines are very
close to each other.
This creates an anisotropy on the observation points: there are much more
observation points along the flight lines directions.

The most widely used source distributions are: a regular grid of point sources
and one point source beneath each observation point.

The \emph{regular grid} creates an homogeneous distribution of point sources
below the surveyed region.
The distance between sources is controlled by the grid spacing parameter.
Keeping the boundaries of the grid constant, reducing the spacing increases the
number of sources.

The \emph{source below data} layout locates one source below each
observation point, therefore the number of sources will be equal to the number
of data points.

When working with ground surveys, the \emph{regular grid} needs the grid
spacing to be sufficiently small so observed values can be accurately
reproduced by the source distribution.
This will create too many sources on areas where no observation has been
carried out.
In contrast, the \emph{source below data} layout is more likely to accurately
fit the observed data with much less sources, reducing the computational load
to fit the equivalent sources' coefficients.

When working with airborne surveys, the \emph{source below data} may
generate an anisotropic distribution of sources by locating too many sources
along the flight paths.
It could lead to unwanted aliases on the predicted values.
In contrast, the \emph{regular grid} won't generate aliases by homogeneously
locating sources.

We propose a new source distribution that could simultaneously reduce the
computational load and remove the drawbacks of the preceding ones: the
\emph{block averaged sources}.
It consist in:

\begin{enumerate}
    \item Dividing the region in blocks of equal size. The size of the blocks
        is controlled by a \emph{spacing} parameter.
        (see Fig.~\ref{fig:block-averaged-sources}(a)-(b)).
    \item Computing the median location of the observation points that fall
        inside each block. Blocks without any observation point are ignored.
    \item Locating one point source below each block averaged coordinate.
        (see Fig.~\ref{fig:block-averaged-sources}(c)).
\end{enumerate}

The number of sources created by this new distribution will be less or equal to
the ones created by the \emph{source below data} and the \emph{regular
grid} with the same spacing.
Moreover, the sources are only located beneath populated blocks, so sources
will be concentrated on regions where data has been gathered and no anisotropic
distribution of sources will be generated.

\begin{figure*}
    \includegraphics[width=\linewidth]{figs/block-averaged-sources-schematics.pdf}
    \caption{
        Block averaged sources.
        (a)~Given a set of observation points
        (b)~we divide the survey region on blocks of equal size and compute the
            median location of the observation points that fall inside each
            block.
        (c)~A source point is located beneath each block averaged coordinate.
            The number of point sources could be less or equal to the number of
            observation points. No source is located beneath unpopulated
            blocks.
    }
    \label{fig:block-averaged-sources}
\end{figure*}

Figure~\ref{fig:source-layouts-schematics} shows (a) an arbitrary set of
observation points that simulates a ground survey, and the possible location of
sources generated by (b) the \emph{sources below data}, (c) the new \emph{block
averaged sources} and (d) the \emph{grid sources} layouts.

\begin{figure*}
    \includegraphics[width=\linewidth]{figs/source-layouts-schematics.pdf}
    \caption{
        Source layouts.
        (a) Set of \SourceLayoutsSchematicsObservations{} synthetic observation
            points that resemble a ground survey.
        (b) Location of the \SourceLayoutsSchematicsSourceBelowData{} sources
            obtained through the \emph{sources below data} layout.
        (c) Location of the \SourceLayoutsSchematicsBlockAveragedSources{}
            sources obtained through the \emph{block averaged sources} layout.
        (d) Location of the \SourceLayoutsSchematicsGridSources{} sources
            obtained through the \emph{grid sources} layout.
    }
    \label{fig:source-layouts-schematics}
\end{figure*}

The depth of the point sources can be chosen following different criteria.
Deep sources generate low frequencies, while shallow ones generate high
frequencies (cite).
The simplest option is to locate all sources at the same depth, which we will
call \emph{constant depth} in the future (see Fig.~\ref{fig:depth-types}(a)).
If the measurement were taken at significantly different altitudes, the
elevated computation points will be more distant to the sources than the lower
ones.
This may create problems on reproducing high frequencies on the elevated
points.

One possible solution is to locate each source below its corresponding
observation (or block averaged) point at a constant \emph{relative depth}
from it.
The depth of each source can be computed as the height of its corresponding
observation (or block averaged) point minus a depth parameter that assumes the
same value for all sources (see Fig.~\ref{fig:depth-types}(b)).
The sources won't be all at the same depth, but they will all be at the same
distance from their corresponding observation (or block averaged) point.

In case our survey presents heavily clustered data points on some areas, we may
want the sources below that region to be shallower in order to reproduce the
high frequencies measured by these clustered observation points.
We can propose a \emph{variable depth} approach: it locates each point source
according to the \emph{relative depth} and then subtracts a term proportional
to the mean distance to its $k$ nearest neighbour sources
(see Fig.~\ref{fig:depth-types}(c)).
So, the depth of the sources can be computed as follows:

\begin{equation}
    \begin{split}
        \textrm{depth} =
           &\textrm{data point height} - \textrm{relative depth} \\
           &- \textrm{depth factor} \cdot \textrm{mean distance}
    \end{split}
\end{equation}

\noindent where \emph{data point height} is the elevation of the corresponding
observation (or block averaged) point, \emph{mean distance} is the mean
distance to the $k$ nearest source neighbours, \emph{depth factor} and
\emph{relative depth} are parameters.
The addition of this new term will make clustered sources to be shallower than
scattered and distant sources.

Similar approaches for setting sources at depths that depend
on the distance to their nearest neighbours were already proposed by
\citet{cordell1992, guspi2004, guspi2009}.

\begin{figure*}
    \includegraphics[width=\linewidth]{figs/depth_types.pdf}
    \caption{
        Depth types for locating point sources. We put one source beneath each
        observation point (station) using:
        (a)~a \emph{constant depth} where all sources are located at the same
           depth,
        (b)~a \emph{relative depth} where all sources are located at the same
           vertical distance from its corresponding observation point, and
        (c)~a \emph{variable depth} where the depth of the sources is
           proportional to the average distance to its neighbour sources.
           Notice how the clustered sources on (c) are relatively shallower
           than the
           other ones.
    }
    \label{fig:depth-types}
\end{figure*}

The combination of the three source layouts with the three strategies to define
the depth of the sources define seven different source distributions (see
Table~\ref{tab:source-distributions}).
The \emph{grid sources} is only compatible with the \emph{constant depth}
scheme if no further information is provided.

\begin{table*}
    \centering
    \caption{
        Source distributions as combinations of source layouts and depth
        strategies.
    }
    \label{tab:source-distributions}
    \begin{tabular}{lccc}
        & Source below data & Block averaged sources & Grid sources \\ \hline
        Constant depth & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
        Relative depth & $\checkmark$ & $\checkmark$ & $\times$     \\
        Variable depth & $\checkmark$ & $\checkmark$ & $\times$     \\
    \end{tabular}
\end{table*}

\subsection{Gradient boosted equivalent sources}

Reducing the number of sources might help to lower the amount of computer
memory needed to fit their coefficients, although it may be not enough for
a very large set of observation points.
Even if we can greatly reduce the number of sources, having too many data
points would still produce a Jacobian matrix large enough that cannot fit in
memory.
This problem was already faced by other authors
\citep{mendonca1994, leao1989, li2010, barnes2011, oliveira2013, siqueira2017,
jirigalatu2019}.
The iterative method proposed by \citet{siqueira2017} needs equivalent sources
to be located beneath each observation point, so it cannot take advantage of
the block-averaged sources.
\citet{leao1989} perform the fitting simultaneously with the prediction, what
prevents us to use already fitted equivalent sources to make future
predictions. Besides the method is limited to interpolations on regular grids.
% Add more discussion on why we won't apply any of the following methods
\citet{mendonca1994}
\citet{li2010}
\citet{barnes2011}
\citet{jirigalatu2019}

Here we propose an iterative algorithm for fitting the source coefficients
using a gradient boosting \citep{friedman2001, friedman2002} strategy:
(i) define a collection of overlapping windows of equal size that cover the
survey area,
(ii) define one set of equivalent sources per window,
(iii) iteratively fit the coefficients of each set of sources.
Once every set of sources is fitted, we can predict the value of the field on
any observation point as the effect of every set of equivalent sources.

Lets assume we have $N$ measurements of a harmonic field on observations points
$\{\mathbf{p}_i\}_{i=1}^{N}$ stored in the vector $\mathbf{d} = (d_1, d_2,
\ldots, d_N)\trans$. We have defined a set of $M$ point sources located on
$\{\mathbf{q}_j\}_{j=1}^{M}$. Instead of trying to fit the entire set of
coefficients $\mathbf{c}$ at once, we can reduce the problem to fitting $K$
different sets of equivalent sources: we define $K$ overlapping windows of
equal size that cover the whole observation area, and then we create one set of
equivalent sources per window formed by the $\{\mathbf{q}_m\}_{m=1}^{M_k}$
sources that fall inside the $k$-th window.
The observed data should be equal to the superposition of the
effect of every set of equivalent sources:

\begin{equation}
    \mathbf{d} = \sum_{k=1}^K \alpha_k \mathbf{A}_k \mathbf{c}_k,
\end{equation}

\noindent where $\mathbf{c}_k$ is the vector of coefficients for the $k$-th
set of equivalent sources; $\mathbf{A}_k$ is the Jacobian matrix between
those sources and every data point; and each $\alpha_k$ is a constant called
\emph{step-size parameter}.

By applying gradient boosting we can fit each $\mathbf{c}_k$ vector
iteratively: on each iteration a residue vector $\mathbf{r}_k$ (initialized
with the observed data) is used to fit the $\mathbf{c}_k$
coefficients and $\alpha_k$ step-size parameter, and then updated by removing
the effect of the same sources, as follows:

\begin{equation}
    \mathbf{r}_0 = \mathbf{d},
\end{equation}

\begin{equation}
    \mathbf{r}_k = \mathbf{r}_{k-1} - \alpha_k \mathbf{A}_k\mathbf{c}_k.
    \label{eq:residue}
\end{equation}

\noindent On each iteration the $\mathbf{c}_k$ vector and the $\alpha_k$
parameter can be fitted so they minimize the misfit function:

\begin{equation}
    \phi(\mathbf{c}_k) =
        \left\lVert
            \mathbf{r}_{k-1} - \alpha_k \mathbf{A}_k\mathbf{c}_k
        \right\rVert ^ 2
        + \lambda_d \left\lVert \mathbf{c}_k \right\rVert ^2,
\end{equation}

\noindent following the same method described on Section
\ref{sec:eql-inversion}.
Because the $\mathbf{A}_k$ matrices have only $N \times M_k$ elements,
adjusting the size of the overlapping windows can help in reducing the computer
memory needed to fit the source coefficients.
Nevertheless, in case we have too many data points that make the $\mathbf{A}_k$
matrices large enough that they cannot be stored in memory, we can apply one
more simplification on the fitting process: ignore the effect of the $k$-th
sources on any observation point that falls outside the $k$-th window.

Assuming that there are $N_k$ observation points that fall under the $k$-th
window, we can fit the $\mathbf{c}_k$ coefficients by minimizing the following
misfit function:

\begin{equation}
    \phi(\mathbf{c}_k) =
        \left\lVert
            \tilde{\mathbf{r}}_{k-1} - \tilde{\mathbf{A}}_k\mathbf{c}_k
        \right\rVert ^ 2
        + \lambda_d \left\lVert \mathbf{c}_k \right\rVert ^2,
\end{equation}

\noindent where $\tilde{\mathbf{r}}_{k-1}$ is the residue vector containing
only the elements that correspond to the $\{\mathbf{p}_n\}_{n=1}^{N_k}$
observation points that fall under the $k$-th window; and
$\tilde{\mathbf{A}}_k$ is the Jacobian matrix between these observation points
and the $k$-th sources.
Because the $\tilde{\mathbf{A}}_k$ matrices will have $N_k \times M_k$
elements, the computer memory needed for fitting the $\mathbf{c}_k$
coefficients is greatly reduced.

Once the $\mathbf{c}_k$ coefficients are fitted following the same method
described on Section \ref{sec:eql-inversion}, we need to obtain the value
of the step-size parameter $\alpha_k$.
This can be achieved by minimizing the norm of the difference between the
previous residue $\mathbf{r}_{k-1}$ and the effect of the $k$-th sources on
every observation point:

\begin{equation}
    \alpha_k = \underset{\alpha}{\mathrm{argmin}}
    \left(
        \left\lVert
            \mathbf{r}_{k-1} - \alpha \mathbf{A}_k \mathbf{c}_k
        \right\rVert ^ 2
    \right),
\end{equation}

\noindent which leads to:

\begin{equation}
    \alpha_k = \frac{
        \mathbf{r}_{k-1}\trans \mathbf{A}_k \mathbf{c}_k
    }{
        \left(\mathbf{A}_k \mathbf{c}_k\right)\trans \mathbf{A}_k \mathbf{c}_k
    }.
\end{equation}

This step will improve the convergence of the iterative algorithm and also will
introduce at some extent the effect of the $k$-th sources on every data point,
which was neglected on the fitting of the $\mathbf{c}_k$ coefficients.

Once both the $\alpha_k$ parameter and the $\mathbf{c}_k$ coefficients are
fitted, equation \ref{eq:residue} is applied to update the residue: compute the
effect of the sources belonging to the $k$-th window on every observation
point. Worth noting that when calculating the effect of any number of sources
we don't need to pre-compute the entire Jacobian matrix: we can calculate the
effect of the sources on each observation point by a simple addition of terms,
what means computing each Jacobian element at once when needed.

Because the number of windows is fixed before starting the iteration process,
its number of steps are also fixed to $K$. Moreover, the windows are randomly
shuffled before starting the process to prevent the prioritization of clustered
sets of equivalent sources.

After all $\alpha_k$ parameters and $\mathbf{c}_k$ coefficients vectors are
fitted, we can predict the effect of every equivalent source on any point as
follows:

\begin{equation}
    V(\mathbf{p}) =
    \sum\limits_{k=1}^K \sum\limits_{m=1}^{M_k}
    \frac{\alpha_k {c_k}_m}{|\mathbf{p} - \mathbf{q}_m|}.
\end{equation}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Comparison of source distributions}

Our first goal is to to compare the performance of all source distributions
from Table~\ref{tab:source-distributions} when predicting harmonic field data
using the equivalent sources technique.
To do so we have created a synthetic model made out of prisms of different
shape and density contrasts.
The gravitational effect of this synthetic model have been computed on
a regular grid (\emph{target} grid) at a constant height and on two different
set of observation points that we will call \emph{synthetic surveys}: a ground
and an airborne survey.
The data from each synthetic survey is interpolated on the points of the
\emph{target} grid and then scored against its values.
We can then quantitatively compare how accurate is each source distribution at
predicting unobserved data on each synthetic survey and quantify the
computational load needed to do it.

\subsection{Synthetic Model}

%Describe forward model made out of prisms.
%Show prisms model?

The synthetic model is made out of \NPrisms{} prisms distributed on a region of
\ModelEasting{}$\times$\ModelNorthing{} between \ModelDepth{} deep and the zero
height plane.
Density contrast of prisms range from \ModelMinDensity{} and
\ModelMaxDensity{}.
We built deep big and thin shallow prisms for creating gravity anomalies with
long and short wavelengths, respectively.

The vertical component of the gravity acceleration generated by the synthetic
model has been computed on a regular grid of
\TargetEastingSize{}$\times$\TargetNorthingSize{} points with a spacing of
\TargetSpacing{} located \TargetHeight{} above the zero height plane
(Fig.~\ref{fig:target-grid}), using \citet{nagy2000} and \citet{nagy2002}.
We will refer to this grid as the \emph{target} grid in the future.

\begin{figure}
    \includegraphics[width=\linewidth]{figs/target-grid.pdf}
    \caption{
        Target grid. Gravitational effect of synthetic model on a regular grid
        composed of \TargetEastingSize{}$\times$\TargetNorthingSize{} points
        with a spacing of \TargetSpacing{} located \TargetHeight{} above the
        zero height plane.
    }
    \label{fig:target-grid}
\end{figure}

\subsection{Synthetic Surveys}

In order to compare the predictive capabilities of each source distribution
under on different surveys, we created a ground and an airborne \emph{synthetic
surveys}.
For creating the synthetic ground survey we selected a portion of the Southern
Africa Gravity Data available through the
\href{https://www.ngdc.noaa.gov/mgg/gravity/gravity.html}{NOAA website}.
For the airborne survey we used a portion of the Great Britain Aeromagnetic
Survey acquired by Hunting Geology and Geophysics Ltd and Canadian Aeroservices
Ltd between 1955 and 1965 and made available by the
\href{https://www.bgs.ac.uk/products/geophysics/aeromagneticRegional.html}{
British Geological Survey (BGS)
}.

On both cases we selected only a portion of the survey and rescaled it to span
on an area of \SurveyEasting{}$\times$\SurveyNorthing{}.
The ground survey is composed by \GroundSurveyPoints{} observation points
distributed at heights ranging between \GroundSurveyMinHeight{} and
\GroundSurveyMaxHeight{} (Fig.~\ref{fig:synthetic-ground-survey}(a)).
While the airborne survey has \AirborneSurveyPoints{} points at heights between
\AirborneSurveyMinHeight{} and \AirborneSurveyMaxHeight{}.
(Fig.~\ref{fig:synthetic-ground-survey}(a)).

The vertical component of the gravity acceleration generated by the synthetic
model has been computed on both surveys.
Some Gaussian noise (with standard deviation of \SurveyNoise{}) has been added
to the effect of the synthetic model to simulate acquisition errors
(Figs.~\ref{fig:synthetic-ground-survey}(b)
and~\ref{fig:synthetic-airborne-survey}(b)).

\begin{figure}
    \includegraphics[width=\linewidth]{figs/ground-survey.pdf}
    \caption{
        Synthetic ground survey.
        (a)~Location of observation points. Altitude given in meters above the
            zero height plane.
        (b)~Vertical component of gravity acceleration generated by the
            synthetic model plus Gaussian noise on the ground survey
            observation points.
    }
    \label{fig:synthetic-ground-survey}
\end{figure}

\begin{figure}
    \includegraphics[width=\linewidth]{figs/airborne-survey.pdf}
    \caption{
        Synthetic airborne survey.
        (a)~Location of observation points. Altitude given in meters above the
            zero height plane.
        (b)~Vertical component of gravity acceleration generated by the
            synthetic model plus Gaussian noise on the airborne survey
            observation points.
        Based upon the Great Britain aeromagnetic data, with the permission of
        the British Geological Survey.
    }
    \label{fig:synthetic-airborne-survey}
\end{figure}

\subsection{Comparisons}

Each source distribution from Table~\ref{tab:source-distributions} needs
certain parameters in order to build the set of point sources.
The prediction capabilities of the source distribution depends on the choice of
these parameters.
For example, locating the sources beneath the data points at constant depth
needs the definition of the \emph{depth} parameter.
If the sources are set too close to the data points, the source distribution
it's very likely to over-fit the data: the measured field will be recovered, but
the predictions on unobserved locations will be very inaccurate.
Another parameter that plays an important role on the predictive capabilities
of the sources is the \emph{damping}.

On real world scenarios, choosing the values of the parameters is a challenging
task: it's not easy to determine the accuracy of the predictions without
knowing the true value of the field on unobserved locations.
This problem can be solved through cross-validation.
When working with a synthetic model, the situation is different: we can compute
the true values of harmonic field generated by the synthetic model on any
point.
Therefore, interpolating the observed data on the same points of the
\emph{target} grid and then scoring the prediction against the true values of
the \emph{target} grid constitutes an objective way to measure the predictive
accuracy of the source distribution.

In order to compare the predictive capabilities of each source distribution we
perform a parameter search to obtain the best prediction that can be achieved
by each one of them.
For each source distribution we proposed different values for each parameter
(see Tables~\ref{tab:parameters-ground-survey}
and~\ref{tab:parameters-airborne-survey}).
These parameters values are combined obtaining several \emph{set of
parameters}.
We use each set of parameters to create the sources, fit their coefficients
through least-squares and predict the field on the same points of the
\emph{target} grid.
We then \emph{score} the prediction by computing the root mean square (RMS)
between the prediction and the true values of the \emph{target} grid.
Finally, we obtain the \emph{best prediction} for each source distribution as
the one that achieves the lowest RMS.
This process is carried out on both ground and airborne synthetic surveys.
See Figure~\ref{fig:flowchart} for a graphical illustration of it.

\begin{figure}
    \includegraphics[width=\linewidth]{figs/flowchart.pdf}
    \caption{
        Flowchart for comparing the performance of the source distributions.
        For each source distribution we propose different values for its
        parameters (see Tables~\ref{tab:parameters-ground-survey}
        and~\ref{tab:parameters-airborne-survey}).
        These values are then combined to obtain several set of parameters
        which are iteratively submitted to the process illustrated on this
        figure.
        Finally we obtain the best prediction generated by each source
        distribution as the one that achieves the best score.
    }
    \label{fig:flowchart}
\end{figure}


Tables~\ref{tab:parameters-ground-survey}
and~\ref{tab:parameters-airborne-survey} also show the parameter combination
that produces the best prediction for each source distribution and its
corresponding RMS score, for both ground and airborne synthetic surveys,
respectively.
Figures~\ref{fig:ground-survey-differences}
and~\ref{fig:airborne-survey-differences} show the differences between the
target grid and the best prediction achieved by each source distribution, for
both ground and airborne synthetic surveys, respectively.

\begin{figure*}
    \includegraphics[width=\linewidth]{figs/ground_survey_differences.pdf}
    \caption{
        Differences between gravitational effects measured on the target grid
        and the ones produced by the best prediction made by each source
        distribution based on the synthetic ground survey.
    }
    \label{fig:ground-survey-differences}
\end{figure*}

\begin{figure*}
    \includegraphics[width=\linewidth]{figs/airborne_survey_differences.pdf}
    \caption{
        Differences between gravitational effects measured on the target grid
        and the ones produced by the best prediction made by each source
        distribution based on the synthetic airborne survey.
    }
    \label{fig:airborne-survey-differences}
\end{figure*}



\subsection{Discussion}

Figures~\ref{fig:ground-survey-differences}
and~\ref{fig:airborne-survey-differences} show that all source distributions
produce accurate predictions, both for the ground and airborne survey.
The RMS scores don't show significant difference, so we can only conclude
that all the source distributions are able to produce comparable predictions.
Nevertheless, the \emph{block averaged sources} make use of less sources to
produce this predictions, what would reduce the computational load needed to
fit the sources coefficients and finally compute the actual prediction.

The RMS doesn't seem to depend on the choice of the depth strategy used to
locate the equivalent sources.
At first glance, the choice of a depth strategy doesn't seem to impact the
computational needs.
Nevertheless, when trying to find the set of parameters that produce the most
accurate predictions through a method like cross-validation, we need to fit the
source coefficients one time per every possible combination of parameters.
A depth strategy like the \emph{variable depth} needs a higher number of
parameters (depth, depth factor, K nearest) than \emph{constant depth} or
\emph{relative depth} (which takes only a depth parameter).
The addition of these new parameters makes the search of the best set more
computationally expensive: more parameters means increasing the dimensions of
the parameters space and thus increasing the number of possible combinations.
Therefore we would be more prone to choose a \emph{constant depth} or
a \emph{relative depth} when dealing with very large datasets in order to save
some computation time.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusions}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Acknowledgements}

We are indebted to the developers and maintainers of the open-source software
without which this work would not have been possible.

The synthetic airborne survey was based upon the Great Britain aeromagnetic
data, reproduced with the permission of the British Geological Survey
$\textcopyright$UKRI\@.
All rights reserved.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix

\section{Source distributions parameters}

\begin{table*}
    \centering
    \caption{
        Parameters used with each source distribution when gridding the
        synthetic ground survey. The table also contains the set of parameters
        that generates the best prediction for each source distribution and its
        corresponding RMS score (in mGal).
    }
    \label{tab:parameters-ground-survey}
    \begin{tabular}{c c l c c c}
        \textbf{Source layout}
            & \textbf{Depth type}
            & \multicolumn{1}{c}{\textbf{Parameters}}
            & \textbf{Values}
            & \textbf{Best}
            & \textbf{RMS (mGal)} \\
        \toprule

        \multirow{8}{*}{Source Below Data}
            & \multirow{2}{*}{Constant Depth}
                & Depth (m)
                & \GroundSourceBelowDataConstantDepthDepth
                & \BestGroundSourceBelowDataConstantDepthDepth
                & \multirow{2}{*}{
                    \BestGroundSourceBelowDataConstantDepthRms
                  } \\
            &
                & Damping
                & \GroundSourceBelowDataConstantDepthDamping
                & \BestGroundSourceBelowDataConstantDepthDamping
                & \\
            \cmidrule{2-6}
            & \multirow{2}{*}{Relative Depth}
                & Depth (m)
                & \GroundSourceBelowDataRelativeDepthDepth
                & \BestGroundSourceBelowDataRelativeDepthDepth
                & \multirow{2}{*}{
                    \BestGroundSourceBelowDataRelativeDepthRms
                  } \\
            &
                & Damping
                & \GroundSourceBelowDataRelativeDepthDamping
                & \BestGroundSourceBelowDataRelativeDepthDamping
                & \\
            \cmidrule{2-6}
            & \multirow{4}{*}{Variable Depth}
                & Depth (m)
                & \GroundSourceBelowDataVariableDepthDepth
                & \BestGroundSourceBelowDataVariableDepthDepth
                & \multirow{4}{*}{
                    \BestGroundSourceBelowDataVariableDepthRms
                  } \\
            &
                & Depth factor
                & \GroundSourceBelowDataVariableDepthDepthFactor
                & \BestGroundSourceBelowDataVariableDepthDepthFactor
                & \\
            &
                & K nearest
                & \GroundSourceBelowDataVariableDepthKNearest
                & \BestGroundSourceBelowDataVariableDepthKNearest
                & \\
            &
                & Damping
                & \GroundSourceBelowDataVariableDepthDamping
                & \BestGroundSourceBelowDataVariableDepthDamping
                & \\
        \midrule

        \multirow{11}{*}{Block Averaged Sources}
            & \multirow{3}{*}{Constant Depth}
                & Depth (m)
                & \GroundBlockAveragedSourcesConstantDepthDepth
                & \BestGroundBlockAveragedSourcesConstantDepthDepth
                & \multirow{3}{*}{
                    \BestGroundBlockAveragedSourcesConstantDepthRms
                  } \\
            &
                & Spacing (m)
                & \GroundBlockAveragedSourcesConstantDepthSpacing
                & \BestGroundBlockAveragedSourcesConstantDepthSpacing
                & \\
            &
                & Damping
                & \GroundBlockAveragedSourcesConstantDepthDamping
                & \BestGroundBlockAveragedSourcesConstantDepthDamping
                & \\
            \cmidrule{2-6}
            & \multirow{3}{*}{Relative Depth}
                & Depth (m)
                & \GroundBlockAveragedSourcesRelativeDepthDepth
                & \BestGroundBlockAveragedSourcesRelativeDepthDepth
                & \multirow{3}{*}{
                    \BestGroundBlockAveragedSourcesRelativeDepthRms
                  } \\
            &
                & Spacing (m)
                & \GroundBlockAveragedSourcesRelativeDepthSpacing
                & \BestGroundBlockAveragedSourcesRelativeDepthSpacing
                & \\
            &
                & Damping
                & \GroundBlockAveragedSourcesRelativeDepthDamping
                & \BestGroundBlockAveragedSourcesRelativeDepthDamping
                & \\
            \cmidrule{2-6}
            & \multirow{5}{*}{Variable Depth}
                & Depth (m)
                & \GroundBlockAveragedSourcesVariableDepthDepth
                & \BestGroundBlockAveragedSourcesVariableDepthDepth
                & \multirow{5}{*}{
                    \BestGroundBlockAveragedSourcesVariableDepthRms
                  } \\
            &
                & Depth factor
                & \GroundBlockAveragedSourcesVariableDepthDepthFactor
                & \BestGroundBlockAveragedSourcesVariableDepthDepthFactor
                & \\
            &
                & K nearest
                & \GroundBlockAveragedSourcesVariableDepthKNearest
                & \BestGroundBlockAveragedSourcesVariableDepthKNearest
                & \\
            &
                & Spacing (m)
                & \GroundBlockAveragedSourcesVariableDepthSpacing
                & \BestGroundBlockAveragedSourcesVariableDepthSpacing
                & \\
            &
                & Damping
                & \GroundBlockAveragedSourcesVariableDepthDamping
                & \BestGroundBlockAveragedSourcesVariableDepthDamping
                & \\
        \midrule

        \multirow{4}{*}{Grid Sources}
            & \multirow{4}{*}{Constant Depth}
                & Depth (m)
                & \GroundGridSourcesConstantDepthDepth
                & \BestGroundGridSourcesConstantDepthDepth
                & \multirow{4}{*}{
                    \BestGroundGridSourcesConstantDepthRms
                  } \\
            &
                & Spacing (m)
                & \GroundGridSourcesConstantDepthSpacing
                & \BestGroundGridSourcesConstantDepthSpacing
                & \\
            &
                & Damping
                & \GroundGridSourcesConstantDepthDamping
                & \BestGroundGridSourcesConstantDepthDamping
                & \\
    \end{tabular}
\end{table*}

\begin{table*}
    \centering
    \caption{
        Parameters used with each source distribution when gridding the
        synthetic airborne survey. The table also contains the set of
        parameters that generates the best prediction for each source
        distribution and its corresponding RMS score (in mGal).
    }
    \label{tab:parameters-airborne-survey}
    \begin{tabular}{c c l c c c}
        \textbf{Source layout}
            & \textbf{Depth type}
            & \multicolumn{1}{c}{\textbf{Parameters}}
            & \textbf{Values}
            & \textbf{Best}
            & \textbf{RMS (mGal)} \\
        \toprule

        \multirow{8}{*}{Source Below Data}
            & \multirow{2}{*}{Constant Depth}
                & Depth (m)
                & \AirborneSourceBelowDataConstantDepthDepth
                & \BestAirborneSourceBelowDataConstantDepthDepth
                & \multirow{2}{*}{
                    \BestAirborneSourceBelowDataConstantDepthRms
                  } \\
            &
                & Damping
                & \AirborneSourceBelowDataConstantDepthDamping
                & \BestAirborneSourceBelowDataConstantDepthDamping
                & \\
            \cmidrule{2-6}
            & \multirow{2}{*}{Relative Depth}
                & Depth (m)
                & \AirborneSourceBelowDataRelativeDepthDepth
                & \BestAirborneSourceBelowDataRelativeDepthDepth
                & \multirow{2}{*}{
                    \BestAirborneSourceBelowDataRelativeDepthRms
                  } \\
            &
                & Damping
                & \AirborneSourceBelowDataRelativeDepthDamping
                & \BestAirborneSourceBelowDataRelativeDepthDamping
                & \\
            \cmidrule{2-6}
            & \multirow{4}{*}{Variable Depth}
                & Depth (m)
                & \AirborneSourceBelowDataVariableDepthDepth
                & \BestAirborneSourceBelowDataVariableDepthDepth
                & \multirow{4}{*}{
                    \BestAirborneSourceBelowDataVariableDepthRms
                  } \\
            &
                & Depth factor
                & \AirborneSourceBelowDataVariableDepthDepthFactor
                & \BestAirborneSourceBelowDataVariableDepthDepthFactor
                & \\
            &
                & K nearest
                & \AirborneSourceBelowDataVariableDepthKNearest
                & \BestAirborneSourceBelowDataVariableDepthKNearest
                & \\
            &
                & Damping
                & \AirborneSourceBelowDataVariableDepthDamping
                & \BestAirborneSourceBelowDataVariableDepthDamping
                & \\
        \midrule

        \multirow{11}{*}{Block Averaged Sources}
            & \multirow{3}{*}{Constant Depth}
                & Depth (m)
                & \AirborneBlockAveragedSourcesConstantDepthDepth
                & \BestAirborneBlockAveragedSourcesConstantDepthDepth
                & \multirow{3}{*}{
                    \BestAirborneBlockAveragedSourcesConstantDepthRms
                  } \\
            &
                & Spacing (m)
                & \AirborneBlockAveragedSourcesConstantDepthSpacing
                & \BestAirborneBlockAveragedSourcesConstantDepthSpacing
                & \\
            &
                & Damping
                & \AirborneBlockAveragedSourcesConstantDepthDamping
                & \BestAirborneBlockAveragedSourcesConstantDepthDamping
                & \\
            \cmidrule{2-6}
            & \multirow{3}{*}{Relative Depth}
                & Depth (m)
                & \AirborneBlockAveragedSourcesRelativeDepthDepth
                & \BestAirborneBlockAveragedSourcesRelativeDepthDepth
                & \multirow{3}{*}{
                    \BestAirborneBlockAveragedSourcesRelativeDepthRms
                  } \\
            &
                & Spacing (m)
                & \AirborneBlockAveragedSourcesRelativeDepthSpacing
                & \BestAirborneBlockAveragedSourcesRelativeDepthSpacing
                & \\
            &
                & Damping
                & \AirborneBlockAveragedSourcesRelativeDepthDamping
                & \BestAirborneBlockAveragedSourcesRelativeDepthDamping
                & \\
            \cmidrule{2-6}
            & \multirow{5}{*}{Variable Depth}
                & Depth (m)
                & \AirborneBlockAveragedSourcesVariableDepthDepth
                & \BestAirborneBlockAveragedSourcesVariableDepthDepth
                & \multirow{5}{*}{
                    \BestAirborneBlockAveragedSourcesVariableDepthRms
                  } \\
            &
                & Depth factor
                & \AirborneBlockAveragedSourcesVariableDepthDepthFactor
                & \BestAirborneBlockAveragedSourcesVariableDepthDepthFactor
                & \\
            &
                & K nearest
                & \AirborneBlockAveragedSourcesVariableDepthKNearest
                & \BestAirborneBlockAveragedSourcesVariableDepthKNearest
                & \\
            &
                & Spacing (m)
                & \AirborneBlockAveragedSourcesVariableDepthSpacing
                & \BestAirborneBlockAveragedSourcesVariableDepthSpacing
                & \\
            &
                & Damping
                & \AirborneBlockAveragedSourcesVariableDepthDamping
                & \BestAirborneBlockAveragedSourcesVariableDepthDamping
                & \\
        \midrule

        \multirow{4}{*}{Grid Sources}
            & \multirow{4}{*}{Constant Depth}
                & Depth (m)
                & \AirborneGridSourcesConstantDepthDepth
                & \BestAirborneGridSourcesConstantDepthDepth
                & \multirow{4}{*}{
                    \BestAirborneGridSourcesConstantDepthRms
                  } \\
            &
                & Spacing (m)
                & \AirborneGridSourcesConstantDepthSpacing
                & \BestAirborneGridSourcesConstantDepthSpacing
                & \\
            &
                & Damping
                & \AirborneGridSourcesConstantDepthDamping
                & \BestAirborneGridSourcesConstantDepthDamping
                & \\
    \end{tabular}
\end{table*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{humannat}
\bibliography{references}

\end{document}
