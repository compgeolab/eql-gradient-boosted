\documentclass[twocolumn]{article}
\usepackage[left=0.7in,right=0.7in,top=1in,bottom=1in]{geometry}
\setlength{\columnsep}{2\columnsep}
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[longend,linesnumbered]{algorithm2e}
\usepackage{graphicx}
\usepackage{siunitx}
\usepackage[round,authoryear,sort]{natbib}
\usepackage{url}
\usepackage[pdftex,colorlinks=true]{hyperref}
\usepackage{fancyhdr}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{setspace}

% Define special units
\DeclareSIUnit\mgal{\milli Gal}

% Define inverse symbol with shorter minus
\newcommand{\inv}{^{\text{-}1}}
\newcommand{\trans}{^{\text{T}}}

% Import files with parameter values generated by notebooks
\newcommand{\Gal}{Gal}
\input{synthetic-surveys.tex}
\input{parameters-ground-survey.tex}
\input{parameters-airborne-survey.tex}
\input{best-parameters-ground-survey.tex}
\input{best-parameters-airborne-survey.tex}
\input{source-layouts-schematics.tex}


% Define title, authors, affiliations and DOI
% ===========================================
\newcommand{\Title}{
    Gradient boosted equivalent sources
}
\newcommand{\Author}{
    S.R. Soler,
    L. Uieda
}
\newcommand{\AuthorAffil}{
    {\large
        Santiago R. Soler$^{1,2}$,
        Leonardo Uieda$^{3}$
    }
    \\[0.4cm]
    {\small $^{1}$CONICET, Argentina (santiago.r.soler@gmail.com)} \\
    {\small $^{2}$Instituto Geofísico Sismológico Volponi, UNSJ, Argentina} \\
    {\small $^{3}$Department of Earth, Ocean and Ecological Sciences, School of Environmental Sciences, University of Liverpool, UK} \\
}
\newcommand{\DOI}{
    doi:\href{https://doi.org/xxx.xxx/xxxxxx}{xxx.xxx/xxxxxx}
}
\newcommand{\DOILink}{
    \href{https://doi.org/xxx.xxx/xxxxxx}{doi.org/xxx.xxx/xxxxxx}
}


% Configure header and hypersetup
% ===============================
\pagestyle{fancy}
\fancyhf{}
\lhead{
    \fontsize{9pt}{12pt}\selectfont
    \Author{}, 2019. \DOI{}
}
\rhead{\fontsize{9pt}{12pt}\selectfont \thepage}
\renewcommand{\headrulewidth}{0pt}
\hypersetup{
    allcolors=blue,
    pdftitle={\Title},
    pdfauthor={\Author},
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title{\Title}
\author{\AuthorAffil}
\date{
    \normalsize
    \today
}
\maketitle

\begin{abstract}
    My abstract
    \\[0.5cm]
    \textbf{Keywords:}
    My keywords
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

Measurements of anomalies in potential fields, like gravity disturbances and
total-field magnetic anomalies, are widely used in geophysical exploration for
their relatively low cost of acquisition.
These data can be surveyed using ground, airborne, shipborne, or satellite
systems.
In ground surveys, the data are often gathered following irregular paths or
networks along the surface of the terrain, leading to highly variable
elevations in mountainous regions.
On airborne surveys, the data are gathered along flight lines, producing a
large number of measurements concentrated along almost straight lines.
Measurement height can also change because of the vertical movement of the
aircraft.
Processing of the data often involves interpolation onto a regular grid at
constant height, both to improve visualization for interpretation purposes as
well as to prepare the data for further processing and modelling (e.g.,
reduction-to-the-pole, derivative calculations, upward continuation, Euler
deconvolution).

Several methods exist in the literature for interpolation in two dimensions,
for example continuous curvature splines in tension \citep{smith1990},
bi-harmonic (thin-plate) splines \citep{sandwell1987}, and kriging \citep{hansen1993}.
These general-purpose methods have limitations when it comes to interpolating
potential field data:
(i) they are not able to take into account the variable height of the
observation points and
(ii) the interpolating functions are not necessarily harmonic functions, which
is the underlying assumption behind many processing techniques
(e.g., upward continuation and vertical derivatives).

A widely used method for interpolating gravity and magnetic data
is the equivalent source technique (also known as equivalent layer, radial
basis functions, or Green's functions interpolation), first introduced by
\citet{dampney1969}.
It consists in fitting a model of elementary sources to the data and using this
model to predict new data values.
Besides interpolation, equivalent sources have been used for
reduction-to-the-pole of magnetic data
\citep{silva1986, nakatsuka2006, guspi2009}, upward
continuation \citep{emilia1973, li2010}, joint processing of gravity gradient
data \citep{barnes2011}, modelling the lithospheric magnetic field
\citep{kother2015}, recovering the magnetic induction vector from
total-field magnetic anomalies \citep{li2020}, and more.

Many variants of the equivalent source technique have been proposed, often
attempting to obtain faster or more accurate solutions.
The key factors that vary between them are: (i) the type of source, (ii)
the location of the sources, and (iii) the solution strategy.
The type of source is most commonly a point mass for gravity or dipole for
magnetics \citep[e.g.,~][]{vonfrese1981, silva1986, mendonca1994, siqueira2017}.
However, right-rectangular prisms \citep[e.g.,][]{barnes2011, jirigalatu2019,
li2020} and tesseroids \citep{bouman2016} have also been used successfully.
In fact, even point sources with a simple inverse distance function, instead of
actual gravity or magnetic fields, can be used as
equivalent sources \citep{cordell1992}.
The sources are often distributed on a regular grid at a constant depth
\citep[e.g.,~][]{leao1989, barnes2011, oliveira2013}
or placed beneath each data point \citep[e.g.,~][]{cordell1992, siqueira2017}.
The model is usually estimated through damped least-squares, which imposes a
heavy computational load when the number of data points is large (e.g.,
airborne and satellite surveys).
To reduce the computational load, \citet{mendonca1994} built the solution
iteratively by incorporating one data point at a time using the ``equivalent
data concept''.
\citet{leao1989} processed the input data using a moving window, only fitting the
data inside the window and predicting observations at the center of the window.
\citet{li2010} and \citet{barnes2011} apply different operations to generate a
sparse representation of the sensitive matrix (respectively, wavelet
compression and quadtree discretization), which significantly improves the
speed of the least-squares solution.
\citet{oliveira2013} parametrized the equivalent layer as a piecewise bivariate
polynomial function, reducing the number of parameters in the solution.
\citet{siqueira2017} developed an iterative solution in which the sensitivity
matrix is transformed into a diagonal matrix with constant terms through the
``excess mass criterion''.
\citet{jirigalatu2019} applied the Gauss-FFT method to speed up the forward
modelling operations and solved the least-squares problem using steepest
descent to avoid calculating the Hessian matrix and solving linear systems.

Many of the existing methods solve under-determined problems, requiring a much
larger number of equivalent sources than the number of data points.
Some achieve greater efficiency by restricting their applications
specific data types \citep{siqueira2017},
interpolating only on regular grids \citep{leao1989},
or requiring already gridded data (CITE PINGA NEW PAPER),
to name a few.
Furthermore, many of the optimizations proposed are also complex to implement
in a computer program, limiting their wider adoption.

In the present study,
we propose a two strategies for reducing the computational load of
the equivalent sources technique:

\begin{enumerate}
    \item Reduce the number of equivalent sources for oversampled surveys
      through a \emph{block-averaging} strategy while maintaining the quality
      of the solution.
    \item Fit the equivalent source model iteratively along overlapping windows
      using a \emph{gradient boosting} algorithm \citep{friedman2001}.
\end{enumerate}

The first strategy consists in dividing the survey area into horizontal blocks
and assign one source to each block, located at the median horizontal location
of the data points. For airborne, shipborne, and satellite surveys, which are
oversampled along tracks, this can greatly reduce the size of the inverse
problem while retaining the same quality of interpolation.

The gradient boosting algorithm allows us to fit the equivalent source model
iteratively by operating on individual overlapping windows.
Thus, our method solves several much smaller least-squares problems instead of
a large one.
This has some similarities with the strategy used by \citet{leao1989} but
without the requirement for sources and predictions to be on regular grids.

Through tests on synthetic data, we show that: (i) the \emph{block-averaged}
sources are able to achieve the same accuracy as other traditional equivalent
source layouts while using a fraction of the number of sources, and (ii) the
\emph{gradient boosting} algorithm greatly reduces the computational memory
required to fit very large datasets without sacrificing prediction accuracy.
Finally, a combination of both strategies are used to process a collection of
around 1.7 million ground gravity data measurements from Australia.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The equivalent sources technique}

The Green's equivalent layer theorem states that any harmonic potential field
generated by any three dimensional physical-property distribution can by
reproduced by a continuous two dimensional surface distribution.
This introduces an ambiguity on the distribution that generates
a potential field: multiple physical-property distributions can generate the
same potential field.
This represents an obstacle for determining the true shape and
physical-property distribution that generates any measured potential field.
Nevertheless this ambiguity can also be exploited for developing pre-processing
techniques like interpolating potential field data.

Approximating the continuous distribution by a finite and discrete density
distribution is the basis of the \emph{equivalent sources technique}
\citep{dampney1969}.
The most common approach is to make use of a set of point sources (the
\emph{equivalent sources}) located beneath the observation points.

A classical approach for applying the equivalent sources technique would be to
propose a set of point sources that generate the same harmonic field that has
been measured.
Lets consider a set of gravity acceleration measurements $g_z$ on points
$\{\mathbf{p}_1, \ldots, \mathbf{p}_N\}$ and a set of point sources with mass
$\{m_1, \ldots, m_M\}$ located on points
$\{\mathbf{q}_1, \ldots, \mathbf{q}_M\}$.
The point sources must generate the same gravity field as the one measured:

\begin{equation}
    g_z(\mathbf{p}) = \mathbf{A} \mathbf{m},
    \label{eq:linear-problem-g}
\end{equation}

\noindent where $g_z(\mathbf{p})$ is the vector containing the measured
field on the points $\mathbf{p}$, $\mathbf{m}$ is the vector containing the
masses of the point sources and $\mathbf{A}$ a matrix whose
elements can be obtained as the vertical component of the gravitational
acceleration measured on $\mathbf{p}$ due to the point mass on $\mathbf{q}$:

\begin{equation}
    a_{ij} = G \frac{(z_i - z_j)}{|\mathbf{p}_i - \mathbf{q}_j|^3},
\end{equation}

\noindent where
$G = \SI{6.674e-11}{\cubic\meter\per\kilogram\per\second\squared}$ is the
universal gravitational constant, $z_i$ and $z_j$ are the vertical components
of the $\mathbf{p}_i$ and $\mathbf{q}_j$ points, respectively.

By solving equation~\ref{eq:linear-problem-g} we can obtain the values of
$\mathbf{m}$ that better reproduce the measured field.
This source distribution along with the fitted masses can be used to predict
gravity values on any point where the potential field has not been measured.


\subsection{Generalized equivalent sources}

It's possible to generalize the equivalent sources technique to any harmonic
field through a Green's function problem, regardless the nature of the field.

By definition, any harmonic field $V$ must satisfy the Laplace's equation:

\begin{equation}
    \nabla^2 V = 0.
\end{equation}

Considering as boundary condition that $V$ is equal to zero at infinity, then
its fundamental solution $\psi$ (also known as Green's function or radial basis
function) must satisfy \citep[p.~210]{vladimirov1979}:

\begin{equation}
    \nabla_\mathbf{p}^2 \psi(\mathbf{p}, \mathbf{q}) =
        - 4\pi \delta(\mathbf{p}, \mathbf{q}),
\end{equation}

\noindent where $\delta(\mathbf{p}, \mathbf{q})$ is the Dirac's delta function
and $\nabla_\mathbf{p}$ symbolize the Nabla operator applied on the coordinates
$\mathbf{p}$.

The fundamental solution of any harmonic field can be obtained as follows
\citep[p.~37]{blakely1995}:

\begin{equation}
    \psi(\mathbf{p}, \mathbf{q})
    =
    \int
    \frac{\delta(\mathbf{p}, \mathbf{q})}{|\mathbf{p} - \mathbf{q}|}
    \textrm{d}v
    =
    \frac{1}{|\mathbf{p} - \mathbf{q}|}.
\end{equation}

This shows that the Green's function associated with any harmonic field is
equal to the inverse of the Euclidean distance between the evaluation and the
source points.
Thus any harmonic field $V$ can be expressed as \citep[p.~37]{blakely1995}:

\begin{equation}
    V(\mathbf{p})
    =
    \int \psi(\mathbf{p}, \mathbf{q}) \rho(\mathbf{q}) d\mathbf{q}
    =
    \int \frac{\rho(\mathbf{q})}{|\mathbf{p} - \mathbf{q}|}  d\mathbf{q},
\end{equation}

\noindent where $\rho(\mathbf{q})$ is the density distribution of a certain
physical-property evaluated on the point $\mathbf{q}$. Following
\citet{dampney1969}, this density distribution can be approximated by a finite
and discrete set of point sources located on $\{\mathbf{q}_1, \ldots,
\mathbf{q}_M\}$:

\begin{equation}
    \rho(\mathbf{q}) =
        \sum\limits_{j=1}^{M} c_j \delta(\mathbf{q} - \mathbf{q_j}),
\end{equation}

\noindent where $c_j$ is a coefficient related to the point source located on
$\mathbf{q}_j$, with the same units as the physical-property.
Then the harmonic field $V$ can be approximated by:

\begin{equation}
    V(\mathbf{p})
    =
    \sum\limits_{j=1}^{M} \frac{c_j}{|\mathbf{p} - \mathbf{q}_j|}.
    \label{eq:eql-field}
\end{equation}

In case we have measured the value of the harmonic field on points
$\{\mathbf{p}_1, \ldots, \mathbf{p}_N\}$, we can adjust the values of the $c$
coefficients so they satisfy:

\begin{equation}
    V(\mathbf{p}_i)
    =
    \sum\limits_{j=1}^{M} \frac{c_j}{|\mathbf{p}_i - \mathbf{q}_j|}
    \quad \forall i=1,\ldots,N.
\end{equation}

This system of linear equations can be written in an more algebraic way:

\begin{equation}
    \mathbf{d} = \mathbf{A} \mathbf{c}
    \label{eq:linear-problem}
\end{equation}

\noindent where $\mathbf{d}$ is a vertical vector containing the measured
values of $V$ on the observation points, $\mathbf{c}$ a vertical vector
containing the $c$ coefficients and $\mathbf{A}$ is the \emph{Jacobian matrix},
whose elements are defined as the Green's function evaluated on each pair of
points $\mathbf{p}$ and $\mathbf{q}$:

\begin{equation}
    a_{ij}
    =
    \psi(\mathbf{p}_i, \mathbf{q}_j)
    =
    \frac{1}{|\mathbf{p}_i - \mathbf{q}_j|}
\end{equation}

By solving equation~\ref{eq:linear-problem} we can obtain the values of
$\mathbf{c}$ that better reproduce the measured field.
Then they can be used to predict the value of the harmonic field on any other
point where no measurement has been taken by evaluating
equation~\ref{eq:eql-field}.


\subsection{Fitting source coefficients}
\label{sec:eql-inversion}

Solving equations~\ref{eq:linear-problem-g} and~\ref{eq:linear-problem} is
equivalent to performing an inversion and thus solving an ill-posed problem by
nature due to the non-uniqueness and the instability of the possible solutions.
Therefore is usually needed to add regularization functions in order to obtain
stable solutions
(\citealp[p.~52]{menke1989}; \citealp{cooper2000}; \citealp{oliveira2013}).

We can obtain the values of the source coefficients $\mathbf{c}$ that better
reproduce the measured field by minimizing an objective or misfit function
$\phi(\mathbf{c})$ through a least squares method:

\begin{equation}
    \phi(\mathbf{c}) =
        \left\lVert
            \mathbf{d} - \mathbf{A}\mathbf{c}
        \right\rVert ^ 2
        + \lambda_d \left\lVert \mathbf{c} \right\rVert ^2,
    \label{eq:misfit-unscaled}
\end{equation}

\noindent where $\left\lVert \cdot \right\rVert ^ 2$ symbolizes the L$_2$ norm
and $\lambda_d$ is a \emph{damping} parameter with the same units as the
Jacobian matrix elements.
The second term of the equation applies a zeroth-order Tikhonov
\citep{tikhonov1977} regularization to stabilize the solution.

In order to simplify the choice of the \emph{damping} parameter we scale the
Jacobian matrix so each column has unit variance.
We define a diagonal matrix $\mathbf{S}$, whose elements corresponds to the
standard deviation of each column of the Jacobian matrix $\mathbf{A}$:

\begin{equation}
    \mathbf{S} =
    \begin{bmatrix}
        \sigma_1 & \cdots &0 \\
        \vdots & \ddots & \vdots \\
        0 & \cdots & \sigma_M
    \end{bmatrix}
    ,
\end{equation}

\noindent so equation~\ref{eq:linear-problem} can be written as:

\begin{equation}
    \mathbf{d}
    =
    \mathbf{A} \mathbf{S}\inv \mathbf{S} \mathbf{c}
    =
    \left[
        \mathbf{A} \mathbf{S}\inv
    \right]
    \left[
        \mathbf{S} \mathbf{c}
    \right]
    =
    \hat{\mathbf{A}} \hat{\mathbf{c}}
\end{equation}

\noindent where $\hat{\mathbf{A}}$ is the scaled Jacobian matrix and
$\hat{\mathbf{c}}$ is a vector containing scaled coefficients.

The misfit function defined on equation~\ref{eq:misfit-unscaled} can be then
rewritten as follows:

\begin{equation}
    \phi(\hat{\mathbf{c}}) =
        \left\lVert \mathbf{d}
        - \hat{\mathbf{A}}\hat{\mathbf{c}} \right\rVert ^ 2
        + \lambda \left\lVert \hat{\mathbf{c}} \right\rVert ^2,
    \label{eq:misfit}
\end{equation}

\noindent where now $\lambda$ is a \emph{dimensionless} damping parameter.

Misfit function from equation~\ref{eq:misfit} is minimized through Cholesky
decomposition.
If the number of observation points is equal or larger to the number of
sources, then the linear problem defined on equation~\ref{eq:linear-problem} is
well- or over-determined, respectively. Therefore, the scaled coefficients that
minimize the misfit function can be obtained through \citep{menke1989}:

\begin{equation}
    \hat{\mathbf{c}} =
        \left[
            \hat{\mathbf{A}}^\text{T} \hat{\mathbf{A}}
            + \lambda^2 \mathbf{I}
        \right]\inv
        \hat{\mathbf{A}}^\text{T}
        \mathbf{d}.
\end{equation}

On the other hand, if there are more sources than observation points, the
problem is under-determined and the scaled coefficients can be obtained as
\citep{menke1989}:

\begin{equation}
    \hat{\mathbf{c}} =
    \hat{\mathbf{A}}^\text{T}
        \left[
            \hat{\mathbf{A}} \hat{\mathbf{A}}^\text{T}
            + \lambda^2 \mathbf{I}
        \right]\inv
        \mathbf{d}.
\end{equation}

Once the scaled coefficients are obtained, the sources' coefficients
$\mathbf{c}$ can be obtained by rescaling
$\hat{\mathbf{c}}$:

\begin{equation}
    \mathbf{c} = \mathbf{S}\inv \hat{\mathbf{c}}.
\end{equation}


\subsection{Gradient boosting}

Gradient boosting was first introduced by \citet{friedman2001, friedman2002} as
a method for fitting additive parametric models of the form

\begin{equation}
  d = \sum_{k=1}^K \alpha_k f(\mathbf{c}_k),
\end{equation}

\noindent where $\alpha_k$ is a scalar coefficient called the \emph{step-size}
and $f$ is a function of the parameter vector $\mathbf{c}_k$.
For linear regression problems, these additive models can be written as the
matrix equation

\begin{equation}
    \mathbf{d} = \sum_{k=1}^K \alpha_k \mathbf{A}_k \mathbf{c}_k \ .
    \label{eq:gb-linear-model}
\end{equation}

We can transform our equivalent source problem in
equation~\ref{eq:linear-problem} into an additive model by
(1) defining a set of $K$ overlapping windows of equal size that cover the
survey area and (2) defining separate sets of equivalent sources, one per
window. Then, the coefficients $\mathbf{c}_k$ relate to the equivalent sources
of the $k$-th window and $\mathbf{A}_k$ is the Jacobian matrix between
those sources and every data point.
Thus, the predicted data are a superposition of the
effects of the $K$ sets of equivalent sources.

The gradient boosting algorithm above works by fitting each component of the
additive model, one at a time, to the residuals of the previous component.
\citet{friedman2001} demonstrates that this corresponds to a steepest-descent
optimization in the so-called ``function space'', with $\alpha_k$ corresponding
to step sizes in steepest descent.
We can modify the gradient boosting algorithm of \citet{friedman2001} to
find the damped least-squares solutions for the $K$ parameters vectors
$\mathbf{c}_k$ and step sizes $\alpha_k$ in equation~\ref{eq:gb-linear-model}:

\begin{algorithm}[!h]
  \DontPrintSemicolon
  \setstretch{1.5}
  define the residual vector: $\mathbf{r}_{0} = \mathbf{d}^o$ \;
  \For{ $k = 1$ \KwTo $K$ }{

    \nllabel{alg:scale}
    $\mathbf{B}_k = \mathbf{A}_k \mathbf{S}_k\inv$ \;

    \nllabel{alg:fit}
    $
     \hat{\mathbf{m}}_k = \left[\mathbf{B}_k\trans \mathbf{W}_k \mathbf{B}_k +
     \lambda \mathbf{I} \right]\inv \mathbf{B}_k\trans \mathbf{W}_k
     \mathbf{r}_{k-1}
    $ \;

    \nllabel{alg:unscale}
    $\hat{\mathbf{c}}_k = \mathbf{S}_k\inv \hat{\mathbf{m}}_k$ \;

    \nllabel{alg:stepsize}
    $
      \alpha_k = \underset{\alpha}{\mathrm{argmin}}
      \left(
        \left\lVert
          \mathbf{r}_{k - 1} - \alpha \mathbf{A}_k \hat{\mathbf{c}}_k
        \right\rVert ^ 2
      \right)
    $ \;

    \nllabel{alg:residual}
    $\mathbf{r}_k = \mathbf{r}_{k - 1} - \alpha_k\mathbf{A}_k \hat{\mathbf{c}}_k$ \;
  }
  \BlankLine
  \setstretch{1}
  \caption{Gradient boosting solution for damped least-squares regression.}
\end{algorithm}

\citet{friedman2002} suggests that introducing randomness into the fitting
process can improve convergence of the solution. To achieve this, we randomize
the order in which the $K$ windows are used in the gradient boosting algorithm.

The $\mathbf{A}_k$ matrices have only $N \times M_k$ elements, which can be
considerably smaller than the $N \times M$ elements of $\mathbf{A}$.
Therefore, the gradient boosting method allows us to fit
equivalent sources models that would produce Jacobian matrices that are larger
than the available computer memory.
Furthermore, we can increase or decrease the size of the overlapping windows as
needed depending on the number of sources in the model and the available
computer memory.

We can improve the efficiency of the algorithm further by using only data
points that fall within the $k$-th window for fitting the sources
(steps \ref{alg:scale} and \ref{alg:fit}),
while using all available data when calculating the step size and residuals
(steps \ref{alg:stepsize} and \ref{alg:residual}).
By doing so, we reduce the Jacobian matrix further to $N_k \times M_k$
elements.
The forward modeling operations performed in steps \ref{alg:stepsize} and
\ref{alg:residual} can be done by a summation
(TODO: ADD EQUATION)
instead of a matrix-vector product, which allows us to avoid computing and
storing the larger $N \times M_k$ Jacobian at any point.
The influence of distance sources on the solution is maintained by using the
entire set of data points when updating the residuals vector.

The step size parameter functions as scaling factor that prevents the algorithm
from worsening the fit to data points outside of the current window.
As such, it improves the converge of the solution and ensures that the
overall misfit decreases with iteration.
The step size that minimizes the misfit function in step \ref{alg:stepsize} of
the algorithm is

\begin{equation}
    \alpha_k = \frac{
      \mathbf{r}_{k-1}\trans \mathbf{A}_k \hat{\mathbf{c}}_k
    }{
      \hat{\mathbf{c}}_k\trans\mathbf{A}_k\trans \mathbf{A}_k \hat{\mathbf{c}}_k
    }.
\end{equation}

After all $\alpha_k$ step sizes and $\hat{\mathbf{c}}_k$ coefficients vectors
are estimated, we can predict the effect of the additive equivalent source
model on any point through the summation

\begin{equation}
    d(\mathbf{p}) =
    \sum\limits_{k=1}^K \sum\limits_{j=1}^{M_k}
    \alpha_k \frac{{c_k}_j}{\left\lVert \mathbf{p} - \mathbf{q}_j \right\rVert}
    \ .
\end{equation}

Our gradient boosting algorithm for overlapping windows is similar to the
``bootstrap inversion'' used in \citet{vonfrese1988}, which also iteratively
fits portions of an equivalent source model to the data residuals.
The key differences are:
(1) the sources in the overlapping portions of the windows are fit more than
once, allowing the algorithm to self-correct for poor solutions to any given
window;
(2) using only data points within the window when fitting the data enables the
use of larger datasets;
(3) experience shows that the step size parameter improves the convergence of
the solution, particularly when using only the data inside the windows for
fitting.


\subsection{Source distributions}

How to choose how many sources to use and where to locate them are not
trivial decisions that play an important role on the accuracy of the
predictions and the computational resources needed to fit the sources'
coefficients.

The chosen distribution of sources should simultaneously reproduce the measured
data on the survey points and be able to make accurate predictions of the
measured harmonic field on non observed locations.

A high number of sources homogeneously distributed on the survey region are
capable of reproducing the observed data. Nevertheless, too many sources will
make the Jacobian matrix too large, what could introduce computational problems
like the inability of storing the matrix on memory or a high computational time
needed to fit the sources' coefficients.
On the other hand, using very few sources will undoubtedly reduce the memory
needs and lower the computational time when fitting the sources' coefficients.
Nevertheless, it could be incapable of making accurate predictions or even
reproducing the measured data if the number of sources is too low.

The choice of the source distribution could also depend on the characteristic
of the survey and how the observation points are distributed on the region.
A ground survey usually consists in observation points located along irregular
paths plus some possible scattered points.
The survey region is usually heterogeneously covered, leaving areas without any
observation.
On the other hand, an airborne survey consists in observation points located
along almost straight flight lines. The measurements are usually taken at
a high frequency, so the observation points along the flight lines are very
close to each other.
This creates an anisotropy on the observation points: there are much more
observation points along the flight lines directions.

The most widely used source distributions are: a regular grid of point sources
and one point source beneath each observation point.

The \emph{regular grid} creates an homogeneous distribution of point sources
below the surveyed region.
The distance between sources is controlled by the grid spacing parameter.
Keeping the boundaries of the grid constant, reducing the spacing increases the
number of sources.

The \emph{source below data} layout locates one source below each
observation point, therefore the number of sources will be equal to the number
of data points.

When working with ground surveys, the \emph{regular grid} needs the grid
spacing to be sufficiently small so observed values can be accurately
reproduced by the source distribution.
This will create too many sources on areas where no observation has been
carried out.
In contrast, the \emph{source below data} layout is more likely to accurately
fit the observed data with much less sources, reducing the computational load
to fit the equivalent sources' coefficients.

When working with airborne surveys, the \emph{source below data} may
generate an anisotropic distribution of sources by locating too many sources
along the flight paths.
It could lead to unwanted aliases on the predicted values.
In contrast, the \emph{regular grid} won't generate aliases by homogeneously
locating sources.

We propose a new source distribution that could simultaneously reduce the
computational load and remove the drawbacks of the preceding ones: the
\emph{block averaged sources}.
It consist in:

\begin{enumerate}
    \item Dividing the region in blocks of equal size. The size of the blocks
        is controlled by a \emph{spacing} parameter.
        (see Fig.~\ref{fig:block-averaged-sources}(a)-(b)).
    \item Computing the median location of the observation points that fall
        inside each block. Blocks without any observation point are ignored.
    \item Locating one point source below each block averaged coordinate.
        (see Fig.~\ref{fig:block-averaged-sources}(c)).
\end{enumerate}

The number of sources created by this new distribution will be less or equal to
the ones created by the \emph{source below data} and the \emph{regular
grid} with the same spacing.
Moreover, the sources are only located beneath populated blocks, so sources
will be concentrated on regions where data has been gathered and no anisotropic
distribution of sources will be generated.

\begin{figure*}
    \includegraphics[width=\linewidth]{figs/block-averaged-sources-schematics.pdf}
    \caption{
        Block averaged sources.
        (a)~Given a set of observation points
        (b)~we divide the survey region on blocks of equal size and compute the
            median location of the observation points that fall inside each
            block.
        (c)~A source point is located beneath each block averaged coordinate.
            The number of point sources could be less or equal to the number of
            observation points. No source is located beneath unpopulated
            blocks.
    }
    \label{fig:block-averaged-sources}
\end{figure*}

Figure~\ref{fig:source-layouts-schematics} shows (a) an arbitrary set of
observation points that simulates a ground survey, and the possible location of
sources generated by (b) the \emph{sources below data}, (c) the new \emph{block
averaged sources} and (d) the \emph{grid sources} layouts.

\begin{figure*}
    \includegraphics[width=\linewidth]{figs/source-layouts-schematics.pdf}
    \caption{
        Source layouts.
        (a) Set of \SourceLayoutsSchematicsObservations{} synthetic observation
            points that resemble a ground survey.
        (b) Location of the \SourceLayoutsSchematicsSourceBelowData{} sources
            obtained through the \emph{sources below data} layout.
        (c) Location of the \SourceLayoutsSchematicsBlockAveragedSources{}
            sources obtained through the \emph{block averaged sources} layout.
        (d) Location of the \SourceLayoutsSchematicsGridSources{} sources
            obtained through the \emph{grid sources} layout.
    }
    \label{fig:source-layouts-schematics}
\end{figure*}

The depth of the point sources can be chosen following different criteria.
Deep sources generate low frequencies, while shallow ones generate high
frequencies (cite).
The simplest option is to locate all sources at the same depth, which we will
call \emph{constant depth} in the future (see Fig.~\ref{fig:depth-types}(a)).
If the measurement were taken at significantly different altitudes, the
elevated computation points will be more distant to the sources than the lower
ones.
This may create problems on reproducing high frequencies on the elevated
points.

One possible solution is to locate each source below its corresponding
observation (or block averaged) point at a constant \emph{relative depth}
from it.
The depth of each source can be computed as the height of its corresponding
observation (or block averaged) point minus a depth parameter that assumes the
same value for all sources (see Fig.~\ref{fig:depth-types}(b)).
The sources won't be all at the same depth, but they will all be at the same
distance from their corresponding observation (or block averaged) point.

In case our survey presents heavily clustered data points on some areas, we may
want the sources below that region to be shallower in order to reproduce the
high frequencies measured by these clustered observation points.
We can propose a \emph{variable depth} approach: it locates each point source
according to the \emph{relative depth} and then subtracts a term proportional
to the mean distance to its $k$ nearest neighbour sources
(see Fig.~\ref{fig:depth-types}(c)).
So, the depth of the sources can be computed as follows:

\begin{equation}
    \begin{split}
        \textrm{depth} =
           &\textrm{data point height} - \textrm{relative depth} \\
           &- \textrm{depth factor} \cdot \textrm{mean distance}
    \end{split}
\end{equation}

\noindent where \emph{data point height} is the elevation of the corresponding
observation (or block averaged) point, \emph{mean distance} is the mean
distance to the $k$ nearest source neighbours, \emph{depth factor} and
\emph{relative depth} are parameters.
The addition of this new term will make clustered sources to be shallower than
scattered and distant sources.

Similar approaches for setting sources at depths that depend
on the distance to their nearest neighbours were already proposed by
\citet{cordell1992, guspi2004, guspi2009}.

\begin{figure*}
    \includegraphics[width=\linewidth]{figs/depth_types.pdf}
    \caption{
        Depth types for locating point sources. We put one source beneath each
        observation point (station) using:
        (a)~a \emph{constant depth} where all sources are located at the same
           depth,
        (b)~a \emph{relative depth} where all sources are located at the same
           vertical distance from its corresponding observation point, and
        (c)~a \emph{variable depth} where the depth of the sources is
           proportional to the average distance to its neighbour sources.
           Notice how the clustered sources on (c) are relatively shallower
           than the
           other ones.
    }
    \label{fig:depth-types}
\end{figure*}

The combination of the three source layouts with the three strategies to define
the depth of the sources define seven different source distributions (see
Table~\ref{tab:source-distributions}).
The \emph{grid sources} is only compatible with the \emph{constant depth}
scheme if no further information is provided.

\begin{table*}
    \centering
    \caption{
        Source distributions as combinations of source layouts and depth
        strategies.
    }
    \label{tab:source-distributions}
    \begin{tabular}{lccc}
        & Source below data & Block averaged sources & Grid sources \\ \hline
        Constant depth & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
        Relative depth & $\checkmark$ & $\checkmark$ & $\times$     \\
        Variable depth & $\checkmark$ & $\checkmark$ & $\times$     \\
    \end{tabular}
\end{table*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Comparison of source distributions}

Our first goal is to to compare the performance of all source distributions
from Table~\ref{tab:source-distributions} when predicting harmonic field data
using the equivalent sources technique.
To do so we have created a synthetic model made out of prisms of different
shape and density contrasts.
The gravitational effect of this synthetic model have been computed on
a regular grid (\emph{target} grid) at a constant height and on two different
set of observation points that we will call \emph{synthetic surveys}: a ground
and an airborne survey.
The data from each synthetic survey is interpolated on the points of the
\emph{target} grid and then scored against its values.
We can then quantitatively compare how accurate is each source distribution at
predicting unobserved data on each synthetic survey and quantify the
computational load needed to do it.

\subsection{Synthetic Model}

%Describe forward model made out of prisms.
%Show prisms model?

The synthetic model is made out of \NPrisms{} prisms distributed on a region of
\ModelEasting{}$\times$\ModelNorthing{} between \ModelDepth{} deep and the zero
height plane.
Density contrast of prisms range from \ModelMinDensity{} and
\ModelMaxDensity{}.
We built deep big and thin shallow prisms for creating gravity anomalies with
long and short wavelengths, respectively.

The vertical component of the gravity acceleration generated by the synthetic
model has been computed on a regular grid of
\TargetEastingSize{}$\times$\TargetNorthingSize{} points with a spacing of
\TargetSpacing{} located \TargetHeight{} above the zero height plane
(Fig.~\ref{fig:target-grid}), using \citet{nagy2000} and \citet{nagy2002}.
We will refer to this grid as the \emph{target} grid in the future.

\begin{figure}
    \includegraphics[width=\linewidth]{figs/target-grid.pdf}
    \caption{
        Target grid. Gravitational effect of synthetic model on a regular grid
        composed of \TargetEastingSize{}$\times$\TargetNorthingSize{} points
        with a spacing of \TargetSpacing{} located \TargetHeight{} above the
        zero height plane.
    }
    \label{fig:target-grid}
\end{figure}

\subsection{Synthetic Surveys}

In order to compare the predictive capabilities of each source distribution
under on different surveys, we created a ground and an airborne \emph{synthetic
surveys}.
For creating the synthetic ground survey we selected a portion of the Southern
Africa Gravity Data available through the
\href{https://www.ngdc.noaa.gov/mgg/gravity/gravity.html}{NOAA website}.
For the airborne survey we used a portion of the Great Britain Aeromagnetic
Survey acquired by Hunting Geology and Geophysics Ltd and Canadian Aeroservices
Ltd between 1955 and 1965 and made available by the
\href{https://www.bgs.ac.uk/products/geophysics/aeromagneticRegional.html}{
British Geological Survey (BGS)
}.

On both cases we selected only a portion of the survey and rescaled it to span
on an area of \SurveyEasting{}$\times$\SurveyNorthing{}.
The ground survey is composed by \GroundSurveyPoints{} observation points
distributed at heights ranging between \GroundSurveyMinHeight{} and
\GroundSurveyMaxHeight{} (Fig.~\ref{fig:synthetic-ground-survey}(a)).
While the airborne survey has \AirborneSurveyPoints{} points at heights between
\AirborneSurveyMinHeight{} and \AirborneSurveyMaxHeight{}.
(Fig.~\ref{fig:synthetic-ground-survey}(a)).

The vertical component of the gravity acceleration generated by the synthetic
model has been computed on both surveys.
Some Gaussian noise (with standard deviation of \SurveyNoise{}) has been added
to the effect of the synthetic model to simulate acquisition errors
(Figs.~\ref{fig:synthetic-ground-survey}(b)
and~\ref{fig:synthetic-airborne-survey}(b)).

\begin{figure}
    \includegraphics[width=\linewidth]{figs/ground-survey.pdf}
    \caption{
        Synthetic ground survey.
        (a)~Location of observation points. Altitude given in meters above the
            zero height plane.
        (b)~Vertical component of gravity acceleration generated by the
            synthetic model plus Gaussian noise on the ground survey
            observation points.
    }
    \label{fig:synthetic-ground-survey}
\end{figure}

\begin{figure}
    \includegraphics[width=\linewidth]{figs/airborne-survey.pdf}
    \caption{
        Synthetic airborne survey.
        (a)~Location of observation points. Altitude given in meters above the
            zero height plane.
        (b)~Vertical component of gravity acceleration generated by the
            synthetic model plus Gaussian noise on the airborne survey
            observation points.
        Based upon the Great Britain aeromagnetic data, with the permission of
        the British Geological Survey.
    }
    \label{fig:synthetic-airborne-survey}
\end{figure}

\subsection{Comparisons}

Each source distribution from Table~\ref{tab:source-distributions} needs
certain parameters in order to build the set of point sources.
The prediction capabilities of the source distribution depends on the choice of
these parameters.
For example, locating the sources beneath the data points at constant depth
needs the definition of the \emph{depth} parameter.
If the sources are set too close to the data points, the source distribution
it's very likely to over-fit the data: the measured field will be recovered, but
the predictions on unobserved locations will be very inaccurate.
Another parameter that plays an important role on the predictive capabilities
of the sources is the \emph{damping}.

On real world scenarios, choosing the values of the parameters is a challenging
task: it's not easy to determine the accuracy of the predictions without
knowing the true value of the field on unobserved locations.
This problem can be solved through cross-validation.
When working with a synthetic model, the situation is different: we can compute
the true values of harmonic field generated by the synthetic model on any
point.
Therefore, interpolating the observed data on the same points of the
\emph{target} grid and then scoring the prediction against the true values of
the \emph{target} grid constitutes an objective way to measure the predictive
accuracy of the source distribution.

In order to compare the predictive capabilities of each source distribution we
perform a parameter search to obtain the best prediction that can be achieved
by each one of them.
For each source distribution we proposed different values for each parameter
(see Tables~\ref{tab:parameters-ground-survey}
and~\ref{tab:parameters-airborne-survey}).
These parameters values are combined obtaining several \emph{set of
parameters}.
We use each set of parameters to create the sources, fit their coefficients
through least-squares and predict the field on the same points of the
\emph{target} grid.
We then \emph{score} the prediction by computing the root mean square (RMS)
between the prediction and the true values of the \emph{target} grid.
Finally, we obtain the \emph{best prediction} for each source distribution as
the one that achieves the lowest RMS.
This process is carried out on both ground and airborne synthetic surveys.
See Figure~\ref{fig:flowchart} for a graphical illustration of it.

\begin{figure}
    \includegraphics[width=\linewidth]{figs/flowchart.pdf}
    \caption{
        Flowchart for comparing the performance of the source distributions.
        For each source distribution we propose different values for its
        parameters (see Tables~\ref{tab:parameters-ground-survey}
        and~\ref{tab:parameters-airborne-survey}).
        These values are then combined to obtain several set of parameters
        which are iteratively submitted to the process illustrated on this
        figure.
        Finally we obtain the best prediction generated by each source
        distribution as the one that achieves the best score.
    }
    \label{fig:flowchart}
\end{figure}


Tables~\ref{tab:parameters-ground-survey}
and~\ref{tab:parameters-airborne-survey} also show the parameter combination
that produces the best prediction for each source distribution and its
corresponding RMS score, for both ground and airborne synthetic surveys,
respectively.
Figures~\ref{fig:ground-survey-differences}
and~\ref{fig:airborne-survey-differences} show the differences between the
target grid and the best prediction achieved by each source distribution, for
both ground and airborne synthetic surveys, respectively.

\begin{figure*}
    \includegraphics[width=\linewidth]{figs/ground_survey_differences.pdf}
    \caption{
        Differences between gravitational effects measured on the target grid
        and the ones produced by the best prediction made by each source
        distribution based on the synthetic ground survey.
    }
    \label{fig:ground-survey-differences}
\end{figure*}

\begin{figure*}
    \includegraphics[width=\linewidth]{figs/airborne_survey_differences.pdf}
    \caption{
        Differences between gravitational effects measured on the target grid
        and the ones produced by the best prediction made by each source
        distribution based on the synthetic airborne survey.
    }
    \label{fig:airborne-survey-differences}
\end{figure*}



\subsection{Discussion}

Figures~\ref{fig:ground-survey-differences}
and~\ref{fig:airborne-survey-differences} show that all source distributions
produce accurate predictions, both for the ground and airborne survey.
The RMS scores don't show significant difference, so we can only conclude
that all the source distributions are able to produce comparable predictions.
Nevertheless, the \emph{block averaged sources} make use of less sources to
produce this predictions, what would reduce the computational load needed to
fit the sources coefficients and finally compute the actual prediction.

The RMS doesn't seem to depend on the choice of the depth strategy used to
locate the equivalent sources.
At first glance, the choice of a depth strategy doesn't seem to impact the
computational needs.
Nevertheless, when trying to find the set of parameters that produce the most
accurate predictions through a method like cross-validation, we need to fit the
source coefficients one time per every possible combination of parameters.
A depth strategy like the \emph{variable depth} needs a higher number of
parameters (depth, depth factor, K nearest) than \emph{constant depth} or
\emph{relative depth} (which takes only a depth parameter).
The addition of these new parameters makes the search of the best set more
computationally expensive: more parameters means increasing the dimensions of
the parameters space and thus increasing the number of possible combinations.
Therefore we would be more prone to choose a \emph{constant depth} or
a \emph{relative depth} when dealing with very large datasets in order to save
some computation time.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusions}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Acknowledgements}

We are indebted to the developers and maintainers of the open-source software
without which this work would not have been possible.

The synthetic airborne survey was based upon the Great Britain aeromagnetic
data, reproduced with the permission of the British Geological Survey
$\textcopyright$UKRI\@.
All rights reserved.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix

\section{Source distributions parameters}

\begin{table*}
    \centering
    \caption{
        Parameters used with each source distribution when gridding the
        synthetic ground survey. The table also contains the set of parameters
        that generates the best prediction for each source distribution and its
        corresponding RMS score (in mGal).
    }
    \label{tab:parameters-ground-survey}
    \begin{tabular}{c c l c c c}
        \textbf{Source layout}
            & \textbf{Depth type}
            & \multicolumn{1}{c}{\textbf{Parameters}}
            & \textbf{Values}
            & \textbf{Best}
            & \textbf{RMS (mGal)} \\
        \toprule

        \multirow{8}{*}{Source Below Data}
            & \multirow{2}{*}{Constant Depth}
                & Depth (m)
                & \GroundSourceBelowDataConstantDepthDepth
                & \BestGroundSourceBelowDataConstantDepthDepth
                & \multirow{2}{*}{
                    \BestGroundSourceBelowDataConstantDepthRms
                  } \\
            &
                & Damping
                & \GroundSourceBelowDataConstantDepthDamping
                & \BestGroundSourceBelowDataConstantDepthDamping
                & \\
            \cmidrule{2-6}
            & \multirow{2}{*}{Relative Depth}
                & Depth (m)
                & \GroundSourceBelowDataRelativeDepthDepth
                & \BestGroundSourceBelowDataRelativeDepthDepth
                & \multirow{2}{*}{
                    \BestGroundSourceBelowDataRelativeDepthRms
                  } \\
            &
                & Damping
                & \GroundSourceBelowDataRelativeDepthDamping
                & \BestGroundSourceBelowDataRelativeDepthDamping
                & \\
            \cmidrule{2-6}
            & \multirow{4}{*}{Variable Depth}
                & Depth (m)
                & \GroundSourceBelowDataVariableDepthDepth
                & \BestGroundSourceBelowDataVariableDepthDepth
                & \multirow{4}{*}{
                    \BestGroundSourceBelowDataVariableDepthRms
                  } \\
            &
                & Depth factor
                & \GroundSourceBelowDataVariableDepthDepthFactor
                & \BestGroundSourceBelowDataVariableDepthDepthFactor
                & \\
            &
                & K nearest
                & \GroundSourceBelowDataVariableDepthKNearest
                & \BestGroundSourceBelowDataVariableDepthKNearest
                & \\
            &
                & Damping
                & \GroundSourceBelowDataVariableDepthDamping
                & \BestGroundSourceBelowDataVariableDepthDamping
                & \\
        \midrule

        \multirow{11}{*}{Block Averaged Sources}
            & \multirow{3}{*}{Constant Depth}
                & Depth (m)
                & \GroundBlockAveragedSourcesConstantDepthDepth
                & \BestGroundBlockAveragedSourcesConstantDepthDepth
                & \multirow{3}{*}{
                    \BestGroundBlockAveragedSourcesConstantDepthRms
                  } \\
            &
                & Spacing (m)
                & \GroundBlockAveragedSourcesConstantDepthSpacing
                & \BestGroundBlockAveragedSourcesConstantDepthSpacing
                & \\
            &
                & Damping
                & \GroundBlockAveragedSourcesConstantDepthDamping
                & \BestGroundBlockAveragedSourcesConstantDepthDamping
                & \\
            \cmidrule{2-6}
            & \multirow{3}{*}{Relative Depth}
                & Depth (m)
                & \GroundBlockAveragedSourcesRelativeDepthDepth
                & \BestGroundBlockAveragedSourcesRelativeDepthDepth
                & \multirow{3}{*}{
                    \BestGroundBlockAveragedSourcesRelativeDepthRms
                  } \\
            &
                & Spacing (m)
                & \GroundBlockAveragedSourcesRelativeDepthSpacing
                & \BestGroundBlockAveragedSourcesRelativeDepthSpacing
                & \\
            &
                & Damping
                & \GroundBlockAveragedSourcesRelativeDepthDamping
                & \BestGroundBlockAveragedSourcesRelativeDepthDamping
                & \\
            \cmidrule{2-6}
            & \multirow{5}{*}{Variable Depth}
                & Depth (m)
                & \GroundBlockAveragedSourcesVariableDepthDepth
                & \BestGroundBlockAveragedSourcesVariableDepthDepth
                & \multirow{5}{*}{
                    \BestGroundBlockAveragedSourcesVariableDepthRms
                  } \\
            &
                & Depth factor
                & \GroundBlockAveragedSourcesVariableDepthDepthFactor
                & \BestGroundBlockAveragedSourcesVariableDepthDepthFactor
                & \\
            &
                & K nearest
                & \GroundBlockAveragedSourcesVariableDepthKNearest
                & \BestGroundBlockAveragedSourcesVariableDepthKNearest
                & \\
            &
                & Spacing (m)
                & \GroundBlockAveragedSourcesVariableDepthSpacing
                & \BestGroundBlockAveragedSourcesVariableDepthSpacing
                & \\
            &
                & Damping
                & \GroundBlockAveragedSourcesVariableDepthDamping
                & \BestGroundBlockAveragedSourcesVariableDepthDamping
                & \\
        \midrule

        \multirow{4}{*}{Grid Sources}
            & \multirow{4}{*}{Constant Depth}
                & Depth (m)
                & \GroundGridSourcesConstantDepthDepth
                & \BestGroundGridSourcesConstantDepthDepth
                & \multirow{4}{*}{
                    \BestGroundGridSourcesConstantDepthRms
                  } \\
            &
                & Spacing (m)
                & \GroundGridSourcesConstantDepthSpacing
                & \BestGroundGridSourcesConstantDepthSpacing
                & \\
            &
                & Damping
                & \GroundGridSourcesConstantDepthDamping
                & \BestGroundGridSourcesConstantDepthDamping
                & \\
    \end{tabular}
\end{table*}

\begin{table*}
    \centering
    \caption{
        Parameters used with each source distribution when gridding the
        synthetic airborne survey. The table also contains the set of
        parameters that generates the best prediction for each source
        distribution and its corresponding RMS score (in mGal).
    }
    \label{tab:parameters-airborne-survey}
    \begin{tabular}{c c l c c c}
        \textbf{Source layout}
            & \textbf{Depth type}
            & \multicolumn{1}{c}{\textbf{Parameters}}
            & \textbf{Values}
            & \textbf{Best}
            & \textbf{RMS (mGal)} \\
        \toprule

        \multirow{8}{*}{Source Below Data}
            & \multirow{2}{*}{Constant Depth}
                & Depth (m)
                & \AirborneSourceBelowDataConstantDepthDepth
                & \BestAirborneSourceBelowDataConstantDepthDepth
                & \multirow{2}{*}{
                    \BestAirborneSourceBelowDataConstantDepthRms
                  } \\
            &
                & Damping
                & \AirborneSourceBelowDataConstantDepthDamping
                & \BestAirborneSourceBelowDataConstantDepthDamping
                & \\
            \cmidrule{2-6}
            & \multirow{2}{*}{Relative Depth}
                & Depth (m)
                & \AirborneSourceBelowDataRelativeDepthDepth
                & \BestAirborneSourceBelowDataRelativeDepthDepth
                & \multirow{2}{*}{
                    \BestAirborneSourceBelowDataRelativeDepthRms
                  } \\
            &
                & Damping
                & \AirborneSourceBelowDataRelativeDepthDamping
                & \BestAirborneSourceBelowDataRelativeDepthDamping
                & \\
            \cmidrule{2-6}
            & \multirow{4}{*}{Variable Depth}
                & Depth (m)
                & \AirborneSourceBelowDataVariableDepthDepth
                & \BestAirborneSourceBelowDataVariableDepthDepth
                & \multirow{4}{*}{
                    \BestAirborneSourceBelowDataVariableDepthRms
                  } \\
            &
                & Depth factor
                & \AirborneSourceBelowDataVariableDepthDepthFactor
                & \BestAirborneSourceBelowDataVariableDepthDepthFactor
                & \\
            &
                & K nearest
                & \AirborneSourceBelowDataVariableDepthKNearest
                & \BestAirborneSourceBelowDataVariableDepthKNearest
                & \\
            &
                & Damping
                & \AirborneSourceBelowDataVariableDepthDamping
                & \BestAirborneSourceBelowDataVariableDepthDamping
                & \\
        \midrule

        \multirow{11}{*}{Block Averaged Sources}
            & \multirow{3}{*}{Constant Depth}
                & Depth (m)
                & \AirborneBlockAveragedSourcesConstantDepthDepth
                & \BestAirborneBlockAveragedSourcesConstantDepthDepth
                & \multirow{3}{*}{
                    \BestAirborneBlockAveragedSourcesConstantDepthRms
                  } \\
            &
                & Spacing (m)
                & \AirborneBlockAveragedSourcesConstantDepthSpacing
                & \BestAirborneBlockAveragedSourcesConstantDepthSpacing
                & \\
            &
                & Damping
                & \AirborneBlockAveragedSourcesConstantDepthDamping
                & \BestAirborneBlockAveragedSourcesConstantDepthDamping
                & \\
            \cmidrule{2-6}
            & \multirow{3}{*}{Relative Depth}
                & Depth (m)
                & \AirborneBlockAveragedSourcesRelativeDepthDepth
                & \BestAirborneBlockAveragedSourcesRelativeDepthDepth
                & \multirow{3}{*}{
                    \BestAirborneBlockAveragedSourcesRelativeDepthRms
                  } \\
            &
                & Spacing (m)
                & \AirborneBlockAveragedSourcesRelativeDepthSpacing
                & \BestAirborneBlockAveragedSourcesRelativeDepthSpacing
                & \\
            &
                & Damping
                & \AirborneBlockAveragedSourcesRelativeDepthDamping
                & \BestAirborneBlockAveragedSourcesRelativeDepthDamping
                & \\
            \cmidrule{2-6}
            & \multirow{5}{*}{Variable Depth}
                & Depth (m)
                & \AirborneBlockAveragedSourcesVariableDepthDepth
                & \BestAirborneBlockAveragedSourcesVariableDepthDepth
                & \multirow{5}{*}{
                    \BestAirborneBlockAveragedSourcesVariableDepthRms
                  } \\
            &
                & Depth factor
                & \AirborneBlockAveragedSourcesVariableDepthDepthFactor
                & \BestAirborneBlockAveragedSourcesVariableDepthDepthFactor
                & \\
            &
                & K nearest
                & \AirborneBlockAveragedSourcesVariableDepthKNearest
                & \BestAirborneBlockAveragedSourcesVariableDepthKNearest
                & \\
            &
                & Spacing (m)
                & \AirborneBlockAveragedSourcesVariableDepthSpacing
                & \BestAirborneBlockAveragedSourcesVariableDepthSpacing
                & \\
            &
                & Damping
                & \AirborneBlockAveragedSourcesVariableDepthDamping
                & \BestAirborneBlockAveragedSourcesVariableDepthDamping
                & \\
        \midrule

        \multirow{4}{*}{Grid Sources}
            & \multirow{4}{*}{Constant Depth}
                & Depth (m)
                & \AirborneGridSourcesConstantDepthDepth
                & \BestAirborneGridSourcesConstantDepthDepth
                & \multirow{4}{*}{
                    \BestAirborneGridSourcesConstantDepthRms
                  } \\
            &
                & Spacing (m)
                & \AirborneGridSourcesConstantDepthSpacing
                & \BestAirborneGridSourcesConstantDepthSpacing
                & \\
            &
                & Damping
                & \AirborneGridSourcesConstantDepthDamping
                & \BestAirborneGridSourcesConstantDepthDamping
                & \\
    \end{tabular}
\end{table*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{humannat}
\bibliography{references}

\end{document}
